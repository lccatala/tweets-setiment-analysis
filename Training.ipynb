{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c29ec7ae",
   "metadata": {},
   "source": [
    "# Tweets sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cd6d2d",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d6928ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 14:47:52.760010: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "import time\n",
    "#SEED = 32\n",
    "SEED = int(time.time())\n",
    "random.seed(SEED)\n",
    "seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa811e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3064a15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import GaussianNoise as GN\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adadelta, Adagrad, RMSprop\n",
    "from keras import regularizers\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler as LRS\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#MANAGEMENT PURPOSES ONLY-\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948c9432",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a73778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = 'data'\n",
    "images_filenames = [x[2] for x in os.walk(os.path.join(data_filepath, 'profile_matrices'))][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d7e1dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(len(images_filenames)):\n",
    "    X.append(np.load(os.path.join(data_filepath, 'profile_matrices', str(i)+'.npy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caf0a9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.load('./data/y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd21f5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7204f5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 768)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e66daa7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3356cb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f77151b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9286d34ac0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "371d6712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(y, n_classes=2):\n",
    "    y_one_hot = np.zeros((len(y), n_classes))\n",
    "    for i in range(len(y)):\n",
    "        y_one_hot[i, y[i]] = 1\n",
    "    return y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5ff0270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = one_hot_encode(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c51e1311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 768)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "746b83ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f92864d4070>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAB6CAYAAABEKROUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABsXklEQVR4nO29W4y1WXrf9V+7zofv1OfumbE949iRhhE4BhmioMgkOLEjFMOdIyFZInh84UhEXBBbUcCHWAq5AG4CkiEBo4CtEBNiGSuJCUQRKMIZJ+PEh4xnMhnsnj58/XV/pzrXrv1yUfVb+/c+tev72jPT09WtvaRSVe39vutd61nP4f8c1nrbMAxZtmVbtmVbtg9Xm7zfA1i2ZVu2ZVu2r31bKvdlW7ZlW7YPYVsq92VbtmVbtg9hWyr3ZVu2ZVu2D2FbKvdlW7ZlW7YPYVsq92VbtmVbtg9he8+Ue2vtu1trn2utfaG19sPv1XOWbdmWbdmW7XJr70Wde2ttJclvJfmuJK8m+YdJ/sQwDL/xNX/Ysi3bsi3bsl1q7xVy/44kXxiG4YvDMJwk+dkk3/sePWvZlm3Zlm3ZSnuvlPtHkvyO/n/14rNlW7ZlW7Zl+zq01feo37bgs1H8p7X26SSfTpK1tbV/9bnnnru6s9bytPCRr2nt/PGL7hmGIa21fj3X+vr63VcTunrS2P2cdzO/2Ww2Gu9V93mO/p+/3+3z6/3vhg71OYv6uIqufF/X5arnvJv1fbftqme+G9osuvZJz5/NZllZWRk9233WcT1pTE965u+GBtB9MplkMpn0/9/NWvh5dcyL1v9ptH4S3y36vz7z3YxrUWP+7+baq8bu57nfRWN/2tgqnRZd+/rrr98bhuH5RWN6r5T7q0k+pv8/muQ1XzAMw08l+akkeeWVV4ZPf/rT/i6ttU7ok5OTrKys9MlNp9POhKur51M4PT0dEW9lZaUz0mw2633Rz/HxcZL0z2ezWVZXV3sfKysrOT09HfWTJGdnZ/265JzgZ2dnOTs7S5Jsb29nOp1mGIacnp72uaysrHShQUmfnJxkbW2t98/YGMtsNuvPmE6nffxnZ2cjZb+yspLpdJrV1dURg/r+2WzWnzGZTPoYk/T76B+a0yfPYG2Oj4+zvb2d09PTJMna2lqnMeOEPisrK339qoJnXltbW6Pnra2t5eTk5BJTWWmzDvzNHG/dupX9/f1LgjabzUbGEVowlo2NjRwdHWU2m/X5MG/W1nx0dnaW6XSa9fX1kbKeTqd9Td1X5cu9vb3s7Oz0PrmG6/jcfMFz+RwZ8bWsuXmb+fK9+Zz+zFtVEZsv3U5OTrK9vd3v8Tqsr69nGIYuqx7T5uZmjo6O+nesKzQ37aAp81tdXe3yxt+mK7SznFR+W1tb6/JNv/DK2tpa52M/h7l7ra14kWXmaJ6B5l6L09PTrK2t5fT0tNPLdGJOs9ksZ2dnfX70zfj//J//8//fJUGB1ld98VW2f5jkW1prH2+trSf5viQ//6QbTCgmOZ1OM5vNcuPGjdF129vbXbCn02mOjo66QK2srPTFuHHjRlZWVvpiJudGYG9vrxsGMzYMigKzYoc5THAEPEk2NjaysrKShw8f5vT0NGdnZ1lbW8vm5mbW1ta6EWCMSbK1tZW1tbWsrq5ma2sr29vbWV9fH13LmGAcxtVay/PPP9/HuL6+PjIqCMr6+nqn2/r6eh48eNAZdHV1dSQgs9ksJycnnVFv3LjRlS3zPT097YpwZWWlM9nJyUkePHhwCV2gAIdhyLPPPjtCRjDpo0eP0lrL1tZW9vb2+v+3bt3q11Y06fmyxq21fOlLX7qkELmf+U4mk/49iu6tt97KZDLJ+vp6VwrQ++zs7JICXVtby+7ubh/LxsbG6P7pdJqVlZUcHx93I398fJz9/f1Mp9M899xzXehtkFmXjY2NrK6ujhSJeQfFDm8yZow3a2OFDw0YQ6XT4eFhhmHI5uZmNjY2utywloyR6zc3N3N6ejoCSox9GIZsbGyM5gHt33777b7ePJ8xn52d5fDwcGQU7eWwDsjh+vp65wVkFJoyfhsQ+j0+Ph59PgxDjo6OcnJykv39/ZyenvY1fPDgQacvffODEbh58+bIgEIjZMm8NplMsrGx0XXZzZs3e7/2uOkbujzzzDN9XvDdk9p7otyHYZgm+VNJ/naS30zy14Zh+PWn3Wc0zG+EAqJAJP5msY1AKpHpD4vMdRB9kTJA+WBgPB7/XZUZlt/I5+joqNInrbXs7OyMlOAilxWBhQ4ICorDwsfnW1tbI2RmN25tba0bEM/FjM4YMZwYDO7HILlfe1GeAwKVnCtKDGOlK6iKtTWqND14pp+9tbXV/wYBVUExX0ErrxHNih3v0D80EJnnU+9FaZsvUcQAABRYRdyep8d4FdhgTL6GZ3g9eCb0MEqHLh6bx1TXwt/Z0zatmZvnZM/SY4Mv/RyACHSra1/Rbn2+gVIdc6W7PWTGBS2gtVG8n8PYuBfjYMNd14fv7BXZo3afzAO0b/m5qr1nde7DMPziMAzfOgzDNw/D8JO/m3s9aFwxhwVoVeghRnVHudZuW/1tC+7+F31Wx+FrQbgwBwxRr/VzPWYjMp5DXyBgrsUl97NhWKNzGorg8PCw38+9doc9do8pSWcsIyXuQzA8bo8X5OIfKz4rdV9jei9yiU0rxoVBsSJb9Ju/uZ5+oJWBgtcZ2hohu1XB81xms1lHbjyv0sT8YOGvyrWiec8HoGHjYOBRx4ih8rOrzLhVBYkS9jw9LngRPqlK3LJQ+7ARMJCo31eD7hCq51RDdKwp8lsNOdf5N9/Bd3xXQaXpxRgqH1VgmaSDQj7D67BH8qR2LXaomlienN0TWmvnsepF8b+acDw4OOh/WxBBTmZOhy9sKIxsqlBUw0EIAgE1qvN8vHgg+2qRLbD87zhiRSQwGXmCq5hrc3OzjwcjUBUbz+S3jQXzQvmBylAmuOhmXj4jpg1dQEpW3Kurq9nc3MwwDCMjZIGv/IFhcAjAa8Y1Nn7cXwXENDUqI6djpG3Fy7qbH00HeBClRDjB82H9KgKuAMMxeocOq/Kpxps1t9K3wmQO29vblzy5RYgdmlQAYaSNsU3mcgxtKq3hJfcH7ZEvh09bazk6OhrRDJqY5tDVcm1l7LHDPzbq0AP6QZuaI6M/P2dnZycnJyeXdAqNtVjkSeBFMff9/f2srq72cGkFFLVdC+Ve3VYnrVprI7ebxXOCBaVa47I7Ozt9EaxUiAvyHeEaBKYyWDJ3izw+Cx2x6f39/ZHySuZosyoNnrO7u5vT09Osr6/38VSXDMZ22MI5AxsBmIlQAc8ehiH7+/ujflG+ZmbTmJwBSVsYGSPCWI6Pj3N8fJzNzc2REuS65Dwv4efa5abNZrOuNLa3t0cM7wR1TUISRz05OekhhYrYqtGrChED4c8c47Uy9Bwnk0kfG2MlB8OcWA8M3cnJSY/72hPD7a+GycYeZN5a67Tyd4ytgorWzr2/k5OTEbgx/QAbFXUzJjcnjllrJyLX19c7PzA/+Da5HEIjV+QQpcOcjB2a4QGtra2NPEl4oLWWg4ODrKysdHkHJWPIDARI8joUs7a2lsPDw1FoBl2CPNSkrHNA5Pf43OsEH3h9zDfwA3K/vb2dg4ODPHr06BIIWNTeq2qZr6gZhdqaWfkk6TH4JJ2JHLNyBQ3ogc8cZzdqrN6B//b/ixQvzxqGoaPHRW5vjQUb1cCUFpbaGDdeyt7e3qiihzk6s+57Z7NZtra2LhkEx4edqISBqwJyRQjr5kSax95a6+uHYalo0GjHIQ4QnsM6Hnddn9XV1Z7Y8hx4xpPa1tZWNwhVWKtRrh5HXSMUlcfLuvhZRl/2ChkH4QHzG3NxKATeqzxXQzKz2XnCfH19fQRemPPW1lbnA4dOPKaK9hkDIAzexOAl4zwGvIIRt0dsb4/m6iDf6/ASytqeKLLvHEINX1U+3djY6Otm2QG5uzLHdDO9Kr8A2IzcWQuviQ2cQYh5/fHjxz3f9bR4e3JNkHsyRu3VclHaZqE3oeyKm0AHBweXUEGS7vZTCWGXioXY2NgYhSJoKGTGCePBQJubmyM0uki5uHSSvw8ODno5oI0baINrXM1BVQH9b25udkarz0/SSxgJzeBhQFsEiyqIx48fjwzFyspKdnZ2kszLH6HR2tpabt++3dfNyJ9KEq+H0TdK5eTkJBsbG3198IL4gf5c6xguc3755ZcvzclGFSWFEuJaK5zV1dVuWECGtSLj7Owse3t7fZx7e3ud3pPJpJcIGh1SYXN4eJi7d+/m7OysIzej9dPT004rnmkFbUUOPQwooA/KtSJ0h13o0/mqhw8fjj73WpmXCScir/AvCpkqKpdKDsOQ5557bgRSPHd4B2Ray1LhWxdGmEbwP+Ot4TH6JcRZn43ydC7FYRk/F9lMziuNbJz8N+FX6zqMAUic//FULEc8Bx57/Phxp9+T2rVQ7k9CQMMwdIVGW4RITGhbPQsIiwexuR6GsCLD/fPCLwrXwPA1I8/1Ri3VC3BcmwoXoyJ7BbiWKDIQCs+khMyGgbEZeVcUikFbhBRI4Hpui1xn+kFY/fnp6WmnN16T16aGsFylYSFKMjKmVniEJnCDPQfGggGu4YpqvEHlPAflZEXA8zF0q6ur2dnZ6euNi+9nm0YY2BqWgB5P8oLoh/CO8yDwKdd63c2XGOSKwqGhlf8iD8nNdHaogPFYGTpO7rlYTt1nzRmgC+iLaw1gfC3Imed4/VwKSSNv5FDtIiNYDW2SUTjPY7KytuxhEF2ea4+Te43wMTiUeH+gwjLJZYQLg1mpQkhntlHOVhLUZxu91WoAGMHhAIcqjDSTseWmj2SuCL2wjNsovTKrEUGNYTIeh6cck9va2rpUcoUBI3RlASW+bk/F9bVWrC6xs/KAflUpQX/Tje+hwdbW1iie63gn9LL7zfpBZ9OP61tr3RMhXroo3GHjT9y1GhKUM3NHCBmX3WHTBBqbb1hLz4/xswZPSp762TUkgmfpvmuzHPizyWSSo6OjkdKDFtPptHtNVvr1GR4LSgfPhDkiU2zq43sUJErNPI4xgNa1jBP5NW2qZ1aNYeU1A4VK04ODg77G9laoVUe52uBdpTP47Ojo6FLFDrJqHqvzNG3p78aNGx3AvZt2LZB7crkuljYMw6geHDcJgrEY/t9WkTgyzHN0dJSDg4Nu1SEyjIfyNnLnucnYa3DZI4oD5WUBNTKlD5Qw40AxwoDVE+A6KwT6TtJ3ddpdm0wmIyVALLJ6I2ass7OzXj9PQpq58d3q6moODw9HqHE6nWZvb28ULwXNOd9hJGTDnJyHy6zMq1DYaOL2V3f33r17/VkWPof6WB+ENUn29/f7evHbiXAEkba2ttZDL6urqz1BV59pQ4eBJnw3m81G6wMfuarGioSx2CAYYVfe9+5nxobSNH/RH54N62TFsgi5w094KexE9j6UunFsdXU1BwcH3Qte5A1UhV3DpqYtYT+vD+tr+bVsVeNF3yTkMTDwouXJCW/rABd9VPDoXJjBAF5SvdfyYUDjzYOmxVXtPTny93fbOH7ADJzMiUMSyAtll8jXgnSMsvjcYRLQLQRfX1+/VMbHPdU1cvM1ZhQzKNe54VnwnXeywZi1OofnGzHa+LDgoGjGWmPQRhlGKP4bhUYlgkNWTnJ5vjwLYSbZnWSUNKqG3Aid9YWxFzGw+YNnJvNSNsdcuc7PdnzZoTHTxMjJa8Y1VrAYGfMolR1GhgguRtA7Fk3D6j15TBXhGZiYPka/1RswT0ADeHBrayvHx8ejndJXuf8VWfLs6tUwHtbZsXOjVgOhRWAKg27UXXnQc8Uzs5fi9aj3eJNg1UXmtyrr/L/oe7yWSifW1rxY6XV8fJytra1LSWXT7cd//Md/ZRiGf23R+lwb5E6rxMRdMvNiWVlAEjAsvDfL0Cf/VyXEc6rAW4FUJOD+nAmfzWbZ3d3tKOVJBohGUs0lY8k8lurP2OFpZreywaC5BM9JNccBoa3HwvMQwpp0tVCRBzGyQGjdHHOsQgnd/Ll33hmxeS2sLM03nk+tbGAeNazkuQ/D0OPBVcm7pLS1NkriLjJyIHQLLWuDp1bLHqFHHdsiI26P7ar4s+Ph/CbRWtfCfEU1TZWbirIBR0768dwaQ7aHRr8UIbBeDp1WMMYYHf6snpTlgu+gMTzMPGuSN0nPg3ju1XDhOdu7s9GsoKsqbPOHeYn+F+kePOPWWi+aQOc9qV0r5W7BTebu0I0bNy7Fs7zws9msV6lQk2phtCEwEiGp4v7ok/JJL2JVnDAvCrG1locPH2Y6nY4y2dXQkDADEW9ubvZrzfgWOBbWTA2SgWbE41wZRCXKMAz9b6qPXFbFXKbTaQ4ODrKxsZHd3d2uiEBVKC3ikxg34osYKYSack0zNso1ORe+x48fd3obvTnebI8BReJyPaNiaGzlQkWPD6OywaJvautZC4QfOjum7kPDQIeLQnJWVkdHRzk7Oz+LhJAh/EF4x2gTmjkcYboz/5pzStIVAXPhWofnzKPwzdbW1sj7gg41fr+zszMCHKynZZPSYHu4e3t7mc3Oq3YcRnIM2iFHAy+qiwzI4DfzlY0CoSEDP+51aIizZajEIgJgGtqLtjE1aGT8NbTl0CAhYSqo/J3XHJ6zscRTs95Y1K6FcjdqQQiT9BK6jY2NEZKEoSaTST98CEZxHPvNN9/sZUPcS/gDxQixfDaIQxpGj1ZOtaFALWSLBAul5coAmHZ/f78f3lQRCMoHd//s7Cz37t3rTL2yMj9Thpgmypj+Tk9P8/LLL/ddc4492wsCgU+n077xCBqxMaUiyK2trTz//POX3FOj7bfffnu0GQshXV9fz6NHj3JycpKbN292Bfvmm2+OkJZpiVJlvsRKb9++3a8/PT3tsXQEArQIX1gxGZU5Jry2tpaNjY2uWLjGG5dA/CgGjBwGo7WWF154ofPrvXv3RkbE3iHrxhpYaYGsW2vdKLKG9s6Ojo56eZ5DS+vr63n55Ze7nHidqP55+PDhaCMc17kM1TLB5w8fPuxyOpmcHxDmXdd4y88++2x/Lp+zNuvr63nmmWc6Kt3e3r4kO9Xow7vQ0cDq8ePHHaAgR5YVG0OqntbX17O2ttaN3AsvvNDBQjX8AAZoYfDR2vnhftYdNK6bTqejEzJ3dnYu5X3Qa7/927+d4+PjHBwcjADcVe3axdwXjccxrerioPQccuCe6r5DTGKLMAlGgu3ubisrK6NdcbViw4uNknUJlRnPrh7ozMJJo69F7r49D6OImujh+VaG7gtBgWZ2i41suBcG9vMtYMyJsdA/x9oeHR2NrvPcLBxOGPt61s/8wLozJgyRa5tpNald/67f4xnYk4CeHgdxbQwh9K9rZxTJrkn6Rpihn9fDPMHvmqRnDbzGIEaXAfNdjZXb+OMdmv6V18wXeBo802Wp5leP1QDHSWsMqBWlET+84jGY7+151zyG+dXr6GuQG4CfcweOHNh7NyiqOqk2P9M6qcoe1x4eHnaeTsY5GMDWByrmbsYwUzKpqhjsArHQi2Kh3lyBYvdpk2aq+myjd7uIKHOak1T8X8Mz9MP3Djl4vJUmIBtXYPgeC9Giszt8jWOKpm1V/CAtj9vuY52X4+t8ThjH4zHC8f2MzwLP+Ksy9ucINaEd80n1tqC50ae9l2Ru0O0SLwIeNmiMA8VjYa+8mMyP17XLDVqjH3jZ/SziD6+f+cGgyN85n2ODwHhAzZWGFSk6VjwMQ994ZWBlMEN/Vx1Va1lxnod1dmjCSN06oSYu6zoyNp+nZDra64YeLsNmrjYUlTdrVZjpVgEqYSBHDbiPaIR1G3zu3NRV7atS7q21L7XW/mlr7bOttc9cfPZMa+2XWmufv/h95932t0iQk/QNIn3QclNhUKNFGMBoE4JSqsgi1Mw4BIPBjVZ5TpKRQsENo0TQLjaL48b4+SGux++KcGFyFDxzoQQsySiZCcPjzllxHB8f9xCCn+U5YUSc+ON70JbDBdzHKXZmXhjSQm0GX1lZGW0qI+afzJNkVbkyFyNM5v3o0aORsrbSgk6Et3wvYwc1E/qggqqiKsfZARiu3TYqZZwAiul02gV3URIaL8SKxYjPYS0blmowrRjpF2+RMZn3CLeh+Cov1mbPs7X5+eyu4Wce0NY09SYur7E9ouoBkSer4VIjbNOM9eFa83IFGYAxH0K4uro6CmFWo+WdpRUYIhtV/q3ECfk5FEM/PjeIENBkMunrs8hAjfjoid++u/ZvDcPwbXINfjjJ3x2G4VuS/N2L/5/aFilYozETyAzDxhUEhwSlCUzyC1T0+PHjJOkJCceWWXQUDsouGdfEXoUYnEBrrY2OC7CL29o82ZSkj6+6gDwLwUTxkGew4BJ3Zi410edNTzW0wzNPTk56LS0HmlkBEVN2fJp5GbnxmQ0icU7HWREQ08rGyGiLz2wICA1gCN56661e4816wl/2Wlx7bYXDuHysA0jJyWPob0VvRVQP5oIWfP7CCy905WElAx0qKKjABxoBUKz4oZM3+9Gcd6ioHQO3u7vbK0eMgg2oknQF7DAYgMKeLQofBXj37t0+9iqnNO9EtYLzyZ+sA7wAbzn5jJdu+llXmJ7QBF5H//h00kVlp/C49YVzeC7MoPHsmzdv5s6dO90QkE9MzgEHQOz09LTnH5CjRaEft/dih+r3JvnOi79/OsnfS/JnnnZTdTWTOcJzKSSK10rFoQK7yT7m0/Flx0a51iEaoxeYx2ELNwiMgcEKWznb2jNXxoqCchmZUYjpg4vJWO3G2nuhGaGh/Bkfz7ALDcPhAnLQlxUVaM1nfvBDdUZF2QiLk3N2Z+2i+l4rDejnaiaj82SeELO3UJUhzQlaxu614dkWSI/bxy8YYUITh1fsNaDUDB48LvOllZK/9+eTyfgsFXthi14lyaYye08eN8asery+1mOpSov7GY+P50ZxYYhdEeaQiD2R2gwO+Bva2pD6O8/PslX5EVl3nD+Zv0TEc4OuXi9/ZgNouvE3gJFw8CL9R1km4zk4OOiVTvZcr2pfLXIfkvyd1tqvtPMXXifJi8MwvH4xkdeTvPBuO7MVv7h/IVMZrTpcYiHx4nphrMh8ml7t23Gzq5isMpAFxoteFYs/qx5LjVcyT66xFwPCTi5vSqnz4n/vYvTnHquVgcfHWBa5y3aBqwJnbYi/e16sBXS0N2OhqYLpNXH8FW9mkSJys3KHN+r1pkUyjglDH/dtuvh4Y9MJw+GqKPeB0WZ8XgOaeczP8NjroWE0FIbXzEYazxMeQWaqAeI+0DnPrGOqeaUkvSrHffmeGnLz2pgulW/rOngsi3Y713nZ03Dux/zo9TLvO/RW4+0u2eV6+sbb9hiqfmMsrIVzDk9qX61y/wPDMHx7ku9J8kOttT/4bm9srX26tfaZ1tpnOA4AIXO826V+CBrH1oL2hmG+0ckxz5deeml0yhv9wMAckEQfVTGenJyMXviRXGYqLwTeghOIdlvtabBIMD4uGpugeJYbdeqbm5tZXV3NSy+9NBIikCLCY8FLzg3Wa6+91qt/YHrGxBhhUFd2+GgDCw0041gHUBXjJ6QxDEMvKeO0QKMu0NyDBw86vV566aURmqvGnvtv3brVaXPv3r3RWjsZZi8DFxf62ePiGhsyvBb3Bb0cJjBfIsSM89GjR/3oi5s3b15CjvymP8bvsAo8lszj5SgXj53QZFVC0+k0b7zxxsirq/FijrngGTZ0BjtGt3gk/D0MQ27cuNF51bzmox6sUJGVt99++xId4XHzdXL59ZTmFfIIbNzimdVos46EYAAhjOfVV1/tJdTkJZgn87eMU5F3fHyce/fuXdqM53FXHqUs0vRlPr/n9/yeLv8VMC5qX1VYZhiG1y5+322t/Y0k35Hkzdbay8MwvN5aeznJ3Svu/akkP5Wcl0LyeUUaLLobscHqkiXjI3nfeuutkes4XLiaCIUTO6urq6PDtswgfgaEX4S6Wawaz6ZVFAfDwGyuvfb13MN90OPRo0cjl5/rnASsTM+LmRclI608GQelbtUIeFwI7iKm83o+fPiwK0AElP9xw508r7Xgfqb/duWJt2tX1Ou+bKSgdf3fgmWB9nq7fxsHexNcwxlJJG29U9jPXlR6iRzAY/TtzT+eI+jboQP6u3PnzqVkL9fQL0jRZXp1LapnfHBwMNo0R1iv8hV/OzdFP2tra/1Mfsf4bVRqKCvJSEEaXHDejedHn54L/fvwM8YDSHSorII684s9kGefffZSzs3PZ5wGYKYHn08mk7z22msdPNWqoEXtK0burbWd1toN/k7yR5L8WpKfT/L9F5d9f5K/+W768ySc5XdiyKgZAoOmyNTDjLhzMBC/HdelcsaInjEQG/ThYlXorIhhPKMx+mX8VdGQsEIZWOmaJtCCGCXWHS/HxmtlZaWjbdMSFO19AFXYqsCgLJMx0xmxMTYn0fgexidEQcy17kRFadUds3hBRo48j3G0Nt/E5HhuVZr1b4cbWmt9bNDNAsbf3u49mUxGST+eDQ8ZOdMHCHZ/f3+0O9p09Nzgr0WhFdbQb7py+M5K3uvKJjTzJyjVb4ayd8nYavgDOnGNY9PQmGuhHfKwKB7Os50Tc2K7njqZzM/bt+zaAB8fH/eNRqYtc6ZhbPBYnXjncDd0gNcNuSTJyRx5ZvW8zD9G/nxWz8f3Nfv7+33cT1PsyVcXlnkxyf/dWvvVJL+c5H8fhuFvJfkLSb6rtfb5JN918f+7amZiXMsko1AHStlb9zlNEOZwJQf3G6WTlEBZEpqxiwSDschOztqVNKKHAR1mIARCQ5lRkkh8lZ2kjkM7JIHgsXlhNpv1120l6fHm6jI75IXSp8rDSo5nctohIamqCGE8BMooYnd3d4TGuJ718NZx1qq11rdfY6i8rdqCaoVHchgPiLV88cUXR0bcSdfj4+OO8r1jeTab5caNG6PEO+vpbetGqpR+Miaeb+UDOneeBAXIyzrsheLOM1Z4o3qmHiellSBLrjM9FxkRb8PnGsozHz161MNji5KvNO/2TuZJXKPlg4ODTmtCrC+//HImk8mobJhQHf1YbmyUHYP3Sa7IG/djtFyqSSVLa22Um0Gm4UOH7KqBsW7hOa21vo41jGiA4h3NyPvBwUHfaQxIovmYCcKZR0dHHYg87WyZrzgsMwzDF5P8Kws+fzvJH/4K+7yEOlg8E8zM6hI9M2BF+QihUbRDKM6CE7phQZL5otXYphkHNMeiLwqv0DAwdqur22hhstHytniPGUQCMuLH84SZ3ZwMQslDE4QB5YpC9Iu2GW910+taVFeYUJhpaA/K91jJe9woKguc+cnXG+HWmnvqmT3uykceE0JLeSm0Bxx4z4EbgMQ8ZP5wvNXeob0so0fWt8pOXQvGXmXJaBPF6T59IFdt0NrnsNC/v8N4IE8oQgx85XmHgmws/T9r7zegmR4801Vd9ugW8RgGEYN/VaWL15I1twfFtfTtyjueZUNs4OJSSGhno1LDjk9q12aH6iIF6MSnkeCNGze6cB4fH48UEPW0dvV40zwu8TvvvNORCgyNQsRI8Eor14WbWUABMDO194R6HNZhfnY1QQqM17X7DinBiOQFjKYseCQ/Uc78JgaapCNrXo+G+8m8oDnncTz77LOX4q+8BJuXEKytrXVhIKZuZeJQieOW0G91dbULOx6YEadDMTbSHNGMggXFv/HGGz3+j/AbEDAW5g1fwBMoae4nMeZjp2ez85LXZ555Jkn6qwExEjXWC01ms/NDs46Ojnoy3GeROwxAIpL+nF+yzFATj3Ih/MDZKFaIeJxG/8iVvbzbt29nfX29h9NsjC2r29vbXQagAz88j0S1z2p5/fXXu4fmUB7PW11dHY3doUWqqaDL+vr66JWG8D18W+cAD/pNTNwHKsbbgE7QxcqVPtE/Hq/3EbAW3M/z4Jfnnnsuzz///IhXaCB6gzb0FrzzpHZt3sS0CBmwUIvqnx3rtlBWyw8x+Q6XzGgHVJzMrSsIvyKoq+KxLDgIyAk1jI7RJz8IVkXB/u0YtvMR0McxX6OaatlRAPRXETbjB7H4xQBWqkaoVpw7OzsjZVTnxmcef3KuJBw/Nk0tfF4v92V+QQHXkyiTeeWHkaXPYrcBYS8F4THGb0R5cHAwQpKsbWttZFS9jvAV8VP377WpsWV7gl4zJ6WN1msIzON38tFr71Ci+bR6TfasoWVr8wPr6pqYF4Zh6HkcG61kXHbpii74h7lW7w3aco2PRcDI8h3rz3pXOsA/jolXgOHP8cLqu1rpD13g5xj8UI1XecV0MqhM0kPMHxjkTrPCrMxZXdRkvuDV1bRCr8qU5jKqRW5SMnYd7WoZ8XBdkpHFXoS23BgTzwUpMNd6rZXMMJxXifg4gmqMaB43TF0F1ffYdeQ7KwgndKpLXZ9rY0i822tsVxll6k0ulRbmBQsga+hko5uvQzlbYfGdQQH31ZBP5VEnYRfxLM3hMVd0VIGvPFCNmHm91qGbT+u1NMen65pVA7LIoNSxwJe1Htx84jyBTxVdNK+6abAagLo+5r0ajqq0u4omNId0uLa+7MP906o8wA/8rvrDIGMRX7kPvmPjm/nsSe1aKPdFiohGcqUqBRbdMS+QLK3WZK+uro7CG4sQYTJ+YYeVbx2fFwpXDLeRhXVfvm9lZWX0Sj4jL3selU4V1VcmA8E7kWhDZNRrb4PfDjuBphmjUXX1jEAXFmK+s1dkj8kxTStfr73n5fVyFYiTvD4zps7d/OMt4a2d150n6cddOO55leKvvGKasra1+oa5OndiZWNjY77x/L213YlUj616s6Zj9aCqcYWmNlh1DqyP+/aJntDNisv3VZDA/V5rrxuf170GKEcrY19vT8jyzBgWGUKPHXmykjZdavOY4PEKKj0O5sj/PsqXe/nM/G4evapdC+VeGb9+x3nui753vLFaa2JTLJIFB+ZdlIjzwthY1MQkfSVzK+ukHD/OtjMHmMR9Yhiqa1tdY37qYf1WphYsP5szvj3mqlDoC2Vv78VjsWFx5Yc/92YZaubdX3Vbub61Nsq1VB5xBQnP5dAxK7DKE4zFXluS7h47dMN1VyE9C1uN35q2CC7VMF6TRUrTyrQqf8YIj9TdjbTqUbrVvRpey0VzrKjUz/M9NYRJXqe2RbzvcXvn+CLdYJ5xIriO0aXRNV/g8CafVW+K6xxD93raOHiezK21+ZlFflZF9BV02FC5gs/HKxvcXNWuhXKnVTTBwvHWHxpvs4FIPp2P8qdkccgBdO3EHc808q9JWQxAPULUpZDJ/FAzu99W6nxGmRzf++Q5FpznEnpyEgg62BWm1h8FWkNWxDGdvLHbTaKKckuXDSYZJXOsXPnuxo0bI9SBYatGx+vhg+FIHlnRLEKuCI09JPp55ZVXRgbLVU7J+IwRrw+x1noMATxYS9xszA4PD/P48eMRvzB/AwiAyuHhYd56661+SFsFHiSuzbvVwNv4uFLKiukqQLQIiZtHHz9+PCrDvEqJUApJApW3i5mnptPppTLfO3fuZBjm+0xMa1qVPVpFsdCu5oZam78KkXkxnnqvjabzPDYiizwY84P3m9jrRh/xbNbTO+v39vZG+sw0sAxT/s2b1GrVW23XJqEKwRa5kGSoIaSPCjVT2lUdhvPtz0aqCPXjx49H24hhimSeJDo9Pb304g+Ij/L08328sMdkt4zfZgCjdph70VtWJpNxGVQyT0TyvZM6ixQ8bzza3d3tc2EOzIv+CHHAYAgFCSqXfsHcBwcHna5mSGiwu7vbFWIVKEoE2Zq+sbGRnZ2d7O3tjehuHnCdL8aYXa1WyNUIGTEzh/39/a6kvC72Aqw42KQynU57XbQRnUMC/I0xnkwmuX379gh1Glzwu6JWz8OG08/gu5pY5Dvq2Nktu0j+dnd3R0YFutm4zmaz0RvSvNY09ktYYU0mkzx48KBXslSPChBTeTvJpXp+vINkLrdW1oQnqzfKtbXU0Uaf/ieTSfb390ebiyyD3F9fNALPHB0ddf6wvECnekyEvSgXgcxms9y+fTt7e3ujU1+f1K4dcrfCrOjL6MfIhdpUSuuqUDkGbWtXKySqgQFB+ZrqDVjpTyaTjlK4v4ZHaDBInZsNSW2gIsrfHJZxfBUU6vg3tLBbareXZxsZGRHTN4xZkbtjiHZZbaSgn9GM6W2F73v8m/FaYfD+3Ol0mvv37488p0X9YOiMvOoaVOXm9bfQJfND5pwruWodUYq7u7sjmlnJuW5/Eeo2wvM46jy8FtwL7Z20hV72MlgL0/0qmtbk9KLrbGipqnHOwSEa/22D7vlXxWY077W+asyV7p4H+gQex4siTOm1cCiHfgnj1JzWIpmmdJRxGdhhMA3W/Psqj4p2bZC7EWRFWuwEZNJ+HR7CYDcf5ELdtwWApOpsNuuo3qibZ3pLtZW1n4VAU645mUwubaZA2Vrw61i5xiVOfg7zAanu7+93ZbYIdddxwsRnZ2f9UDF7E6AZ5uu4N8fTevOXXVsjF5SVEa5j2OyQRTihOWPDW4ImuJ88h00y/M8YCFetr6/3d6jak2O+btASYd3e3h7R07RzzNy0ZF0ODw9HZYyLYtHJ+GXl7DWo7201DReVxzJ3P3/RxidoWfnu7Oz85dyL+uM1ew6TLULE5l/AUzV+rDfrZoOJx2MaJ3Ol7v6qd8lz7Ukh1w7rAWwWrQuyZCVKP+gGh3vu3LnT6YO3AI8ZVNlYwOd4LwZDvs5htWq06pgfPXo0qtypIcTargVyr4rCVju5nPzgCAEjLSN2ewAVFRCH43PuNzKFmAgJY6qGx2OnL2LnjueB/n2P51GTPZ6H5wjzEpYiPm7BTcaVCkZv0MwVK0auwzCP/ZsZUfhV+Xl8rB9zMXKvMUgL62Qy6ULDfGgWBrvTVajwzNj9aLRmgw2C9Nir4q60X4TAjczp33XI8E+9h/Fsbm6ODg+zITDvVpRpheLyw7oOrY1PJzXPer9FlTmAjJ/neytSxLCwfmz8Mw0tu/AkSomxWCaqF3MVLQxmvB7cZ1oyJs/BfLToedxTdYANFf14DS07pkH1fOBzjFkdt8dsbwrvmvj7k9q1QO7VolmpuNSRxqH11d3zjxfMIQmjEiuYmnziOwTYzGHBMLOgoBxTdwLXwoHnYEZY1J//J5QA2uNQJMZJTJ54uJOtyXjTiZ/huYC0vSsX74Rx8v8imjnRyeeMl3HVyqbK/IzBinURAmV+JLlXV1dz8+bNfhphMhZq0BxzqvPnu+rKe3425jaevNmHcRIiNF8zRpQgO3K9RhhxGyHnTeBL7nPY0IrJJ06aZxm76YsxQs4cO3ac2PPnM4fQaqgJenoTEqENgw97kfS7yOsyqIBnnDD1elkZGuzU0I95mJ2uPIvxA24MJhxu9bX0VWv1LVOWCcI35o9q1KzUMQZPS6Ym1wS5J/MFsVVEAZNsRPBu3brViXd2dtarOpL0RBcKCGZyzJ2jctn+7AOQYCSy34QojJqs5BxXYys96NdW2cyLMvZWah8FUIWRRfZr9lpr/WhUvnds0MxCIwzg3X9GB9AcemAsQGgwGPsEMK7Qh3CZ4/zkCIZhuHRYkxNxGC+2+/O/kZ8FxXkAjpeYzWb58pe/PBL+6mmxfvAEhujw8LCvgcNDFmoL7Orqak9Mw3MWfIe74BEqR1ZWVnL79u0R+vL8Njc3+2mHTghaadobXaT04GcrSuSHLfPm6SR9Vy78VSs/auzYB3fx+crK/JWDyB4/3P/gwYOOghmTFTLjT+YhRoMS5LrKu4GQn2/5td6oMnZwcJCDg4ORDM9ms14my9ys1PGQHNqtxzssQu6Mf3Nzsx9Yht6xDjKAINHNmiwqM3Vrlfnfj/bKK68Mn/70+YucqkCy+M66W6HwN8SppwE6DGACG9G7GsRGxn0YibgZ/VTmArU49lndfK7jzBj6pJ9KEyMufhvpYmCcbLVysIvrcdKXUa1Rs72nilTseRnR8x3zsKDy/yLlZbe4lqIZ4dozAPFsb2+PXi9XE08VVdbPbeC9TklGMd3qHRpRYzQqKjf9qZxxmMS8Z+RZjaibPRgjeHs5pptj0xXtY4j9flH373WuqLLSDvojA5ZR54/M48zdnrbntLKy0j1DGsrW8muE7HBk9TTdUMwYHeZVPWvzVaVn7duGtXoWrIu9GusEj90AK5nz+8rKSn70R3/0V4b5+6tH7anIvbX2V1prd1trv6bPnmmt/VJr7fMXv+/oux9prX2htfa51toffVr/nnBV7KAC0JkRL6jCG3aYNAT5yEc+0nekssAcDrS6utoPDjs9Pe1JJqPy2Wz8DkiYEwaE6EZKyfhEQJJHZi6+29nZGSVd79y50624mZ5nHxwc5PT0tCN+5mcjN5vNRmGgGud79dVXR0rWoRCQub0OaGX337E+Pjs8PMz9+/dHLj393rp1K8Mw5JVXXun0Jm5IRRLVP/fv38+jR4/SWsvLL788SsBaIftl2tvb2x3lv/XWWyOvzJ6T//ehVa3Nz0VBICuSYi2TeRzfB12x/pS9ucqB6x89epSjo6McHh72Q8eszOC9ra2tjnSdeLaiRgkxhhrWc37BfHd8fJw33nhjdKAaffr4YOjl8FANt3l+k8mk8zOInF2/IF7m8/Dhw46qHfPe3d3NyclJL5WczWY98YwXRd8uGDAyhn70jyx4f8psNruUB0vmYcXDw8N+/dnZWb70pS91OXCsHMBzfHw8yldA87Ozs9y9e7fPsYYjk/NE/s2bN0e8R/OR3icnJ/nEJz6Rzc3N0ea+J7WnIvd2/uq8vST/4zAMn7r47C8meWcYhr/QWvvhJHeGYfgzrbVPJvmZnL+R6ZUk/0eSbx2G4YkBIpA7zGJ0acLbHYHZEVAjIRMIprTbxqYoYmnJ+GCmauXrgljIjCySuZKkgSKpNknmbjRMwX0gACMBxoDStlAOw9ANmhGb0YYbyLImhRzTTcYveebwMMaDInYVjJ9dUa/75bn12RhAFMXW1tbo9Wr20pK54qweAyElFJ49C68RPFFRJjy1sbHR180VOr6nzgGa44EtMq7VTa8eDs9Ixi8lZ8zJvITWLzt3iAG6EOKqPFfnjDInZHTjxo0edvPzjIRtYFpro5NKWd+KfllbgIIryDxPrxd7GRxK2dzcHG2KspFnTQwC7Dn4TJ3qZTC36iVVg+l7qmfLfBZVz/ge5gL6BsQuKhpwCBWwxTxms1l+/Md//CtH7sMw/P0k75SPvzfJT1/8/dNJ/l19/rPDMBwPw/Avknwh54r+ic0KFIuYzMMJoCyuTcaCy/nioEKYDIGzO+MNCTXBYiUAcRmbF5LneuwgCl5AAHN4c5IVQ5IuSDCxKyAW0ejx48cj5by9vd3DL85J2Nuo1RF4JGZyexa1rI7SOHsF9gzMvAh1DQkwxqpQHdO0oiN2jzCh2BFS8whz5jongt2M0h3uYS0pi3WIzuEn6OMQgZONeCHMEaRaXfqzs7N+pKz3RFh5s55ee8vHyspKPzHQO1m9FouOtIVP/Ux7NvSDQYcefL4ICC4CYtxz1TqB2P3eWubFta21Lsvw7MrKedkp/cJLk8lkhMSt2DEOfgFHBQbcZ0/SINNHilQ9UeWJa+wR8RzTycdH28AZSPlobvOD3wn7pPaVJlRfHIbh9YvJvJ7khYvPP5Lkd3TdqxefXWpNL8imuqGi4OTyQUfJ+LQ0FsIKlX5AcItQOC46fbl+mnCMXSXu9eJyvfv2Z8k4+ePxG62QkCGJRuN7GLvW8vL2IJq9mSqIPJOzV6rhMv2tYGpFg42b6YkLXStxEJYko9CXn8eu1CR9O3Yy373Htaaz+0ERUYlSlU1dC641LzEfxowwOjlWq3jYTOe9E6w1NfpGgCSzNzY2cvPmzS60BhNG8EaR9ohM/+qlGfVZnqzAMJ5V8dCXN9WYH2urXiYhUHuCDjHS/8OHD7thqXxIyKQmpu0FeP2v8n64pu4c5z48UDdoBQ/Qn98YZdrbANVyRq5x1RSNeUIzFw74ufYaT05Ocvv27dHheHX8tb2rhGpr7ZuS/MIwD8s8GIbhtr6/PwzDndbaX0ryD4Zh+KsXn//lJL84DMPPPan/V155ZfiBH/iBEVNi4R0DhiBYNAhTrevp6WnW19dz//79S6c0EpM7OjrqVRFra2uXErEo/FqaZHeUZrfK7imIbhiGEaL1d0n68y9oNqp0SOYIhNglJZR3797Ns88+25lna2urv70dw2ZjMJ1O88ILL+TRo0eduaEzY0JJce4HmzAIYdnL8Emca2vnLza+d+/eyIVP0hXa22+/3bfd2xPa3NzMw4cPe3x+Mpnk0aNHefjwYY9HEgeHJicnJ6Nz4BGmj370o3njjTdGRog1oVYf95Yw1+rq+cs9UHoOB3gdHCIAABAWYB7T6fzFL9BrZeV8k9vu7m6m02keP36cR48e5fnnn7+0A7G1+ftciX0bbWNkMJqbm5uXQmrw+XQ67RunjHJv3rzZzzOpeQxer8iaco9RphN8zN8KC8/Fm25YA/jk7bff7vQ0QNjc3Mz6+noePHjQkb2TqB4zym8Y5lVKllvW28d24F2tr6/3l3AwR/pwqeF0Os3t27fz6NGj7jlaJ2xtbWU6nXadRF/QYXt7u/O2c3ToHgDRxsbG6MRadAEGdHV1Na+99lqee+65kV76yZ/8ySvDMl9pnfubrbWXh2F4vbX2cpK7F5+/muRjuu6jSV57Wme2xLaOKD8LHgwCw3tLPu4ki2nhAAWAXFjMZF5ymcwrOA4PD3uoh3i+3TIjBrufxBNBGYzFJU0OMfE3r2szuuBvFtO7WIdh6Lsxk3nC1WNjvDwLGl21KzKZn8rnhJ5dcxQaew0Qytls1kvc6Aflzf03b94c9YdBZG1hdu41GqrxZ58UisBOp9O8+uqrI8HnO5Bp9QA4C4cyQIcOjPi4h+YXM6Po8HQcSqqe1cHBQX/LFYbHNIJn7EGYJ+r4rdjNV84DVITOoWD2VlprPTTFm6DYoFRDovxGrlxRY6AAz9ozSZK33367P8dGx2vMHgCMjIGOw5wYD3vazNtxcBvQityhEWvj85MI+Tgq4PwdPLa7u9vDbEb2DtG4jLKWB9MPPApdkYFhGLKzs9PDWfDok9pXGpb5+STff/H39yf5m/r8+1prG621jyf5lpy/PPuJzYvPpPjcqNiVKXwPkxJjRDlNp9M8++yzl970bibymSBeBMdOzQQ1WZKMy5qMslggKkOS8e5MrL7nsb29fSk2aKHY398fxSxv3LjRE7Uw3MrKSj8UqnoYwzDk/v37Iw/DBscCwHh5Zq1rr7Hbk5OTnJycjI4uSObKCuYEtfhY12S+NZ8642E4Pz2QMUJ/Gz7TEU+uxi+hD+NivLytHqF1SKX2zxrYENadyPCNKzu4H5Dy+PHjJPNqKhLAXp9Fb1Cyt5fM3x7l8EkyTnba0JhPT09P8+DBgxHPOjQCUmQNvNW+xuFNl9Za38TEd+wDqB65/zYP4kndv39/FNaw5wBfVv1hsGLPcHNzc/QCda43TfgbxX52dtZBxnQ6zZtvvtk9YAME1pCd0fA7Y5xOp7l3794oIVz1VgWKzpeZZ/G6n1bb7vZuSiF/Jsk/SPJ7W2uvttb+ZJK/kOS7WmufT/JdF/9nGIZfT/LXkvxGkr+V5IeGp1TK0CxItLr4DotY0LjO4ZMko4QVzzAjc18lmJW5mdd9XdBm9BslaGFc1D/XuxLFYQM/y8+0sPPD4vN8KxOE3DS1F8NYFvUDHVzChnKwa1xRnZPhjMVnWnMt11d0XOnhe2xY/VyjKbyX6glWFOW8gtfIvGF6VIXi/s2nRq0oJfOtaYtC8fpwTVXw9Zq6VhVw2NCYDjzb86tzJERQcxc2MP4M3vCZTzaY5lvCSfCmx4QiN02qAjYIpD/42XJn/nN+rc7X64ZHb4Q/mZyfxnpVHos51twH3/tMJusez8dr6/+d7G6t9Xf5Vj15VXuqGRiG4U9c8dUfvuL6n0zyk0998pOf2YURhZnMGRyUbkvqDTbeOER/MBNhEhASKNSbiHDlTEQrw2qA/Ht7e3tkkdntyb0Wturyo9h9refNb8a3t7fXBYHQjYXGSqp6JMyD+DnPQgBADTC63e3j4+MeazRN/DwYmZjp2tpa3wVKI3TiTTIog0XCh+dUlRdJrdZaXnzxxezt7V0yXszJzzBqcvy2bkyhOXyCG+2wA88yXV2m2tq8nO3g4KCHX0y3ivCszCovGuSYt6A7yNsokX0SHit8sbOz0xFozUFVkAQNHBogd+S4dFV2hFkAMouUIn0TVjHgqcYP4MDLuqEX83V4zjKNbjGNfQyy58A59fCAy62rF2L6VHoZdFDhB/KHV8y3NorQxAeHVcBR27U5fiC5XBFRkaqViJEezUqC2KKVqfu025yMX8Zcn2FE5rZI+Tt5u+i+ivgcj/fLLKoRqUgHBnF1ipEpjFyrgNgEYdQDTWwsLXCeg9F69aQsBJ4nY6yeFNcZ7XtjDoJr5e6YvsNHjM3nyXOd58Nv1t+KsipJ84wN4JN4wOtR+Zb14ezvqtQZD/08jXfME4sMUUXsNKNYKxyeQViT7/l80dytSDkGBDoSdqoeDuFIH25mIEEOwyE2K07oA2Ku/OhcjOnhEJpDluYBlKy9A78/ogIOh/LqGnEv/dfXfmJsHZozne15TSaTXjJc1+yqdq2OH2ASyVhoNjY2egwwmWfv+RsU51rxigSSjCy9z6RgUUEtk8l5vToxRCoriHcT80zSqyNgBiNRK2OHGBizUXTNklsYQA9J+qmHXMPzQcgIlcMpKBLHFJ234Dc0B5l7wwhzIDeA92Rak4hyAoz5VpTEM0kEEwogeeVyOiMjC5XjsVb0eBqui7eScC0/KGxvby/b29sdWYMEXQXhcMaiBLfXDRra8CRzg0XMP8nCeeCBVsVr5eExeU3tbdVaent/NRzgMIoTxczPcoexIs/iqhjPidj/MAw9Cc56M3YrXIetmD/zcIKY8SBjLhKABvw9mUy6Z2+Pwl6VeYe1nM1mI+UMDztUxmf1wLoKEqEBY7TX6rCSaeKDAa3v2GS3srKSP/fn/txXvonp69UWMS7C6QQJTAUToXCSMZKEUAgw1hgiexchC00fFgKYaxGaT8YvvUAxGnk5lFDnW5FHRcWeczJHIsxlZ2dnVH5lRWIkZBfcSRrPw8aCax3egW7My6ExxlvfXsXnCL4TyBhC1pB18+c1XGOX1Qldv3Tl3r17l5QWvxnvotgndGPuFkYjNpqrpuwp1bUzArdyADiYtz0+nlGfx9+ew6JwgNeyKnd4wIiaEs2zs/OSTgoRnoTcMUA0/833KGAneEks29vwHCo9HQN3UQT0q0UMpjN9UH/Pc1whB+8QUrIMJHOPE4Ppda5FEtXIG9QYUMHLW1tbvdCgAu06Dx/Utgi81nYtjvxN5kxkNAhzcyob1zk+nswXDgttpkDpOAbpmtgkI9TLj8+KQPlbSVblC2NzrgVCj3vpxWDBzEQWDDMWNJnN5kd+0qfPLp9Opz0kYe/Bz4AORrRWOjwLIWFzkWPNVLW4jA0auNLHRoUSOwuJlR99G50l89CClS/9u34fj2d1dTUvvPDCiJ/cvG5WuHhk/G8lb4Xr+TqcVpUBxseI1AI+m52ffW6FUo2BUWjlCRsVh4LM8+QDDEp4jgEJ92BwWmvZ29sbGU+eWccAP7Eu9R6HG5GzYZiX8Nack2lQZQ2+qZuPKGG1XFX5h3dcycVYvDbUmVfjAjixl8E9zJk5+nmmOfRgrlwLH9hg0Op4HEGwgbiqXTvk7gVnAk6UgMRZGBiLXWSghGT++jWIBKGMcBEw+kcxJ+MXe/i3FXsNwXC/lXfdEYgChmlcx15j9lU4J5NJNyC89MEoOZkndWez2aUzWo6OjnoM0QjOyhgjgQvd2rwGmuushFEyyfzl3xZ4H9aVpJdC2l23gudzqhQW8YkRK5vZFnlLTpIb8bCHoXox9GHkTrNHZGPsZFgdr0tO4SF7Gk6in52d9YQn60UzMnRZntG8lcfq6mo3pjYewzD08lbPq3oAi9bRc+E6VxmZnsgpsmt0Xela+cfnJ/k9DgYtjMXAjn6sK5y8NVgz/RgXihPAgGF69OhR9xo8D8/Zhp1CCkpKbaBYV3t0Bo7wP/T1uG/cuDFS/h8I5W7lZdeJ/2sCEGI6VEC8FMFznzAM8U62tftwKJgZhib0YWVGnNxWvZYdogQdv0OpmQGMPomFe25eVAswxog5OV7rcsBkvuvO/Vipu2qEZyfz+OXq6mrfZMGmEsbizS01BGN33cLpl2r45EG7wnhWCBZrTv9maHtmVUl6kxs0RxEk6XXMRshWvNCFig4UDfxp403i0MoNOtQwgfc8wCM8n2QyXuSisIUNbA0dWdkDHmyIUUo+1gE6Iic2kA71QWMbdMejzWNGzMSMWR+8JIe5rPTreP2ay/oqSitZx6ypQCF8iMzaEFgeeDYJy9lsnuNaX18fgR0bPBsKV2wZUFr51/Ar9DWPAkiRd6+h5Z7vn9SuhXJPxpZ/ESK0ovV7HlkkFJ3DLiBcv87u8PCwb+LwqXpGUyDe5PKrvqxg7A57W7oZt8YDmReKjOuIc1ZX2rRhYVEct2/f7te5NtjJSGfzNzY2sre3Nwpp8FNj5ShDQlIwFMJVvZ/pdNoRoYVmMpm/V/bZZ58dXV+NyebmZg4ODrqnc+PGjVEops7NCgTmJ+YOf/g+e06OdSfp9fEoIWiHEoVHvN6EqOwtst70Z/7GgB8cHPR32ZqH7cksCsvw20rC/MQ84ScUFXOiz8PDw1Gs2MYCsGFPlnmBMBmHjSvjIKHOPVyLXHK0gPNg9IncOoyKocbYYyxMAydfMR78OFfjkBXzrrkHjBjGgSOIAUMcwwG9kUkf82Ag6rNlqlHAO93d3e2fm2c4YI6xc3QH3oivXdSuTbXMD/zAD4wIboZLcmmRKuLCZcOKwkRra2ujeuIa4vA5KTC1XTOY0OOwoCXjxBKM6LgYFS3cw/d+449R0iKLDFKyIIEWfW9yLtiOAdpI3LhxozMNigUlTt2yPQi/pcoM7etQCEYXVjgcWYChcBKSZ+7t7XUvjX4eP37c48CM3wjRSjiZe1EIEWVmGHkjpIqaNzY2RscgwA9WBkaVCDXrDUjACDBHXHmO0zXyNPq0UTUaXuT6M3/O16muuj3fWhEym81y48aNXtlhD85nLFnhVQ+Ne6B1vRYF+/Dhw2xvb4/kkjWvRtvKGhCGzPtsI3accj1/OzxpjwfZxsBUYFM9gGpojo6OsrOzMypjrCGtyWQyOnfessg5PjbUGKpqLOFLxgGoYj5UcXH96elpfuInfuJrfrbM17yZuFagtnZcV3d8WkFhyWezWXeNuC+Zvz6PheZ7St94JtYYw2Gj4PHaHURBOllj9FORHN9bID1WX286VGFGIFBCnFefjN9aNZlM+jEBVmyO1aKgcGHpFwPC85inlR3fV4Hd3t7uSMMJVLvR6+vrl07xrOWaPNte1DAMPbGM1+SXudgjY6xWAvTNyzq41glRI1zudYgH19pG0PzG/2yDPz097aER91l5wIDGY2VNauUG/FSNgvu0F2ZDyXHYhAUqqrXis7KvtPF5TbU+vI7PvGm+tjy11vouT8qFHcJxyMT3MO96/rnlxg0asK4O2RqomZbQYjqdjvSHdY6VtXnZpdXwBgaI51EyalC1yDBe1a5NWCZZXOGQZCGBIHZVjF6EWgqWzC2tY+LJGPFAZMfD7Ap6DEZJyWVk7xhZXWCHBowQa98wK8kZJ5CsAOnPIZqK3HFV3Tw309mbUKxkarjHfdcx13uhvas9EAJv5jBNbfihi9fUiejKJ0bd/o7vLaSLPIPKFzaIddOZn2Vwwv8Y+rrLcJHSMPqrytUKsfJb/dtjQYG5xNU/rgqpzfT2mrtBA+bt55qGVvj+rsqD52Fj7jG68quG6+hzkZ4wn/pvrnf5Jt8ZENm7sndgveQ8UH2ux0/+xzRJ5m/6cogTT8z8cVW7Fsq9CoMVFyiFLDIxS5Dj9vZ2f4EEChlUc3Bw0F8GfHR01Im9s7OT2WyW+/fvd/ebc85xIYl7EgdnwUAIjkESYoGBHEt06AVGQpEdHx/3heXALB9wRMOTSNJDGKenp7l37173RMgx8D3MzsasYTivkrhx40Z2dnb6c+jXyV02LxEb9tuNCFUYKeMWP/PMMyPEaCMxmUzy9ttvd7TiuDI7W0FAhBqoux6GYeQ94YGADB88eNBDKp/4xCe6UbJxQLGxGY6+qShhKzg0YL8ClTh8xvzoD2GmRA+vCB6DNq21PrfT09N86UtfSpLR+tHgA+K/NSTJ9fBQMg/lAWh8+qdDM6urq7l9+/aoYMAeWWst+/v7XW6MFL2r17yNgUHG8KT8smm8liT5xm/8xn498koIbWVlpYfIqAgDYCHfrqaBhg4Tmaf39/dHFVvIb32DE3y4ubmZnZ2d7v2tra3lueee6x4850HRF2vrMJxj/i5EsELm+gcPHuSdd97pcyAsCb+A5Dc2NvLmm2/29x0YNF7VrkVYxorPFtHM5IOMQGrDMIyO57RrOp2en6JmRO2E0mQy6Qk7n3jIAoAIrLSt1BYhBCNgx6IXoRDisBiIjY2NXpliNMN9jG8Yhh7ffu6550auKDTAVTXCxmC98cYbo6SXQ0hGn3xv+lYk6/5J0pnRPedhGPLcc8+NkLtDTSjDR48e9T5ffPHFPo8a7iCcMwznJWI03s/pOcFDCM0wDF2IWBuUKEJmz8QljKYrYRijbebn0x3xSN5+++3+zJs3b45i4l534svmJdMc+jIHeNVzdL6A+2hvvPHGKOxi2mIAXLHCdy5D5L5aQeNqlDt37ox4AXrev3+/rym8STs5OcnR0dHobV/es2FPlecSOrHc0T+7hC2/FfWaV+FzeHQYhrz++usjQ13DtNVDov/ZbJZ33nlntHYGsQAdF4EAPoZhGL3ofTqd5mMf+1jOzs566GyRh+V2LZC7W3WTknRlxY8rSrCcDglwr2vS7TLZ4rkfK2ssfC0jq4xq45HMjQKKsN5nI+aqBJ5pl9uLx/9OhILc6MMo14xvpeyQjL+rz0JB2G0HoSIEtdV+mC+onxCPla6fj0eEgqrPWOQSQweQjOcOLZJx4s9r6GQVRs1jdGjJ62KeYdw1tOOxQm9/5rWv80RhVRrwPCsX1ofPmVftnzHXiiMbOO59WmjGz0AhmreqQfUYzYsO31RZtCGv68V3fovRImDk0Egdv+nFuqCYzSt1Xf0cQrccxka/gDF4w/OzLnCYtK6Xw7TJPHnssOaT2rs58vevtNbuttZ+TZ/9aGvty621z178/DF99yOttS+01j7XWvujT+u/tpr0IJwAKgZdwzz7+/s5Ozvr9eXch3JmYazIYB6XarlOlXt5K43jzPXwn6ogHe/mMyoTqnLgXrudRjM8l0WnHyz97u5u39jAmFtr/XV2RmfMy/F/7+ZF6EimzmbnR6Ayf97Ow1Zp7+BlvK6pt0B59+4wDP3t8slcobTW+uesr5OhpksVkNu3b4/O0vEpnAgOyAseQhjpB+VcN/7Qj/sCVYGyqMf3i6Jdbmc6EBKAfvU8d9fBoxgqgvamvup92LBZWUFHQieVz/Ds4IO6OY9n0RfPwztN5i+BN89aFpETbwBz3z7l0yjY8WwrWWjqODX0YL04I95om8Z4aBWgJenhSfSFT8Hk+tXV1VHpKyCI8GD1FAxI0BGsF2Fa6OJYPCFVh4We1N4Ncv8fknz3gs//y2EYvu3i5xcviPXJJN+X5F+6uOe/bq09udI+l9G6kVkyfkF2Mn6HKhNHSVaF6374m+uMCBA2hJqzU3DVk/mbX7jOSRMMiZNEKDy788l4Nytzdla8MiFojRCSjQSCwjj5zMwOfb2xhtBQRXwIFy4tdEfwarWCvQJ2CRtRVBff68c42HRFHN70Nn+w1tCDNXA+wu+IpQ8rvIpKmTuCQo7H28p5jtcFxcF8yPnwXFfweC1ZL4xk9RTgX4xPRd6OoZs/XI1CczzcvGVlyP30gdtvpV+9SK+tjQdrbYPD/0bA5IRqYt9y4QqXaqAN2ky7ZB4H93p7DoytHiNugOc5efzVMDAmaGZ6MiZX7Pk+ZI88jI0o1xweHo42A7rs0yDmqvZU5T4Mw99P8s7Trrto35vkZ4dhOB6G4V8k+UKS73gXzxgxUGUkb7Cx8jAyqsoeS+v/YUBvOOIzx8ZhhspIVVFYifnzijJqSR/NpZf8rnFij5PEbi1JtJI18rHbyw8H/pvONoRW1tDKa2C31fN3jLKiKytOlFN1pZm/K5QsFJUnvO6gN+gBbeoYaTYW/F+Fy3Ooa1eVceULf+8+oJPXzMDGish5gzrf2revMS1rHx5fvdfGthYAQP8KliwnSUZKsOa6nI+gP+bCsxxWrA3FXD2RSl+vCfdVb4/Pfb3XxutZdY9DTZUv/JmN3KKQJ7SpoKeulYEU9f+LDOOi9tXE3P9Ua+2ftPOwzZ2Lzz6S5Hd0zasXn11qrbVPt9Y+01r7DMitnttALTA7xJgo1SKTyXlVAi9Ktqu7srLSkSQ7zobh3NXf2dnJ2dn5K+RsGSHgMAz9GpjdiUWsJgjr7OysVyeQ4V5ZOa+VpeogmSsOFCxuGy7+4eFhd/F5LgtJX94hd+/evU7P4+Pj/o5FhIaNQNDz4OAgzzzzTH/JLj8X69ERKJtt3nnnnV5Rwvh51yv10uwVWF1d7QlsBABFzr3379+/VFqGu5mc15pvb2/n5s2b/X8rAG/nPjw87HkWn8fx8Y9/PEl69YwVJnSG1naDb9682UMr8E6SvglnbW1t9J7V4+Pj0WvzHGZaWVkZ0clGjVcjfvnLX84wzM8dQrGwtlSsMB4UBPxh9E2o0fefnZ31UBoKg/nh2le3n2qUhw8fZn9/f3REg9G4ec61/VTG8Pl0Os0777zTQ12E+L7hG74hSfpu6QpI1tbWsr+/3xVkzQ9QSeSdq4SGUOyrq/OXdDj8gUfO5jgn92/dupWtra3cunVr5NHxP4bH4bkaXqteBLILbwDO+Pvhw4edRsk4v8BOfDx75J1jEqiEu6q9qx2qrbVvSvILwzB86uL/F5PcSzIk+YkkLw/D8B+01v5Skn8wDMNfvbjuLyf5xWEYfu5J/b/yyivDD/7gD46Y1YjTihui8vvsbLwjkHtWVs7LqBxjhEhJeiIS5MECG3UbfVzMZ2SFFyEB79z0tUYoVmw8DwWQjM+rMbqru9ostMwfA+U5exxHR0ejahrmX5Gp6WuDwTj8Yg7GYG+B+x0eIf6JInbFC3F+mH99fT1bW1ujg5fsVdCnUTff13i5Y5heNxs2XqCBYXLi2s+v93INygxltMhr4HvWyGOtSBD+qHNG4bAWDhtWOuHpVc8N4OQx+r6a+LVM+Dk0b6oijGU+cD8oWqN85o8B5S1F8Jrj9fZGZrP5u31dMukNfYAQe0Pwqz3DqlssO1S1cb93WTN+b4g0vdkhbS/RvFvXl34dPqXPnZ2dkWdxdnaWH/uxH/vanuc+DMObwzCcDcMwS/LfZh56eTXJx3TpR5O89rT+KoNZaU0mk142hqLf2trqCNsxUvqAMC6PZCGcJDVj2YXC2voQK7vLPMcuJMp5f3+/MzhozYlBzzdJr4U1iqjC45IwW3/vigPBJvNwD/ShISR+p6mVETQ7OjrK6ur5a9c4eRJlQ5kaiNJupBNnCBceEWNkHrjYTlKbtq21UX7BSppr7caDSr/85S+bTy+5xP7N/CeTSTciGOd6jISVPIpze3s7k8mkx1XtZtsLpA/4isS0Fan5kD7t/jt3Ak/a+MK3vs4lgkm6p1uP08DIcMRzPfTK/O71gR+RM4wXn2P0aj/In08DRZGjqBmjq01chog8bm9v9+M2mDd0gQ/Je5mOixLeIGIXbJD8NgCyvPB7d3d3JN+sBWWL1msYV+ZaY+4VhPAZugtZqzv1a/uKlHtr7WX9++8loZLm55N8X2tto7X28STfkuSXn9bfVd4DwuVKGCYJs5B1BhGYiPSBkrU1RPGxOO6f/2FcmN8WmVbjjCQhjcZcAsh87dIRbrFy8xyYhxkSZYtCsZvthFtNniFU1UthDq7QmE6no5ePUOkBDU0T5ozxMUJlTqwnytjIx3TxnG0YrvqMMYP2fY1bjWlWIIExgpdoi4wyc2A+niN0qP0wBkI1NebqvnxsQR2DPQPHxx0rruPiM16FR7PM4NVWekPjmiepYKzyGfPgfvjEoSPPseZ1nEjleq6pRyhURMzzMQiLjlyw0cGoGYgBBg2gnN9wZY5zUchLBYCWuVp44XttRNEdGM4aUntSe+omptbazyT5ziTPtdZeTfKfJfnO1tq35Tws86UkP3gxmF9vrf21JL+RZJrkh4ZhePo+2fmz+sQdb/PmhSQj6w0yQEEm49dluUEUBM+17VZYyXxjxNnZ2Yjp3acXwQobwWTBqYP1tTyTn7pZygreJVpWUBy2xXf8Dfp0/I4+ndcwejaj8Tlub1XCxDjNoFUZ2EiCyGBUFDsxXh8dYONCf1aqph2fe9PPs88+O+Kl6vJiFJ0oG4ZhtJPQisiGz/MzwjOqp9Gvy0P5fzqdZm9vr8/HitnuukNtfA5Pmp89X5p5x3kOms9Mgae2t7e78jcg8dq7EYowH9nwOP8Cb81ms374lcNii/q2twZN/f7ZZJ5b8WYl90mIDTm2HLiBppkH83bo0cCghsqojjKoMv35zT3e0bwoSczcbRDgTcbCfVe1a3Mq5Kc//enOACAf/q8WHqaye8b2cB/+44UxGucgK0IMhF9I4tAwMGw59oImi1FDRe0orHraXjI/fbAKJvdbqQ7DeSKZWClGypt+YIi9vb3s7u6OYp70bwGEto4hJvMdccMwZHd3N/v7+z1ebmRa51gNH8qMLD8G2DFdx2BrMsqC7aSi6QMaxcW9efNm7t+/3w1H9QpQmsRCoS0vMbFSqHFRu8L+HOPFufyuEOFaG+tHjx4lOT/SGIPj62peoYIQH/lq5ck8oR8yYp5DkdvrMgjBMyOnYpBQ+Z9nmO/9LPo2oGCdKFl1c+7MoUiMBOEzwlIeSw0/8RkJZMbiuD1K1314j4RzJCRBk3kVF3ScTqc9gY4uYjyMwbkyNwyP9wrw2eHh4Shef3BwkBs3bnR+a609MeZ+LY4fSMaoHUaAmFhcmMsI/fDwsMf4krmLXpN+xOVOT09zcHCQ9fX17O7uXqoGsTWczWb9hEUUGEJeY/AoRI7IZU6rq6vZ29sbveXFSAZBpcKG+TucwnMQ8t3d3Uyn09y+fbtv4mqtdcVy586d0Uux2WCxvb2dBw8epLXWj0F27oLqCBRycq6Itre3s7e3NwrJMD8YHyauyVpCaMNwvh2dKoxk/voyhGgymfR47NraWra3t/u11bhS076yspLnn3++u8+//du/3c+N91pZiFtro+3tVpI2fIyNa+yteLMSMd3Dw8Ou4ElcG8la+F966aV+rrk9NuZq4+Hvq7dVPTcneOFnaOC8ictzCQ/CC+QSvI6Ek0wzDCjN96DUkUHT87XXXsszzzzTAQP3khzGuJD/QZFxlg20r0deMyfWHtBmZehkqzfigdJR1i68QKkSOjVKB7D4nCEfew2vWsdB92E4PzoD5M/JnAYQ0PH4+DgvvfRSP1PJZ9xc1a6Nck8uV6OwIEzESJHrnLAhrg4zmXH4zBUYyRxt14w4i+M3CyFwRpgV/VCWaYaxm28j5bAMzMz3dgH5DEVAxQOlnDCBqyhgfhg7mZ+r7mNFjZTqaYXQlfuMYI3UeaYrmux5IIT1DUPQDCQGreib+ypN+A7mpmSSmOTZ2dloS/wwzBO7DhfRV2vn59xbEfNslEGN1aNozJOAihqPrfyM0bJn5rU2iDC/89uoE4/V+Rr4GhnhuUaunr89XGTACqp6BTR7NqyJDQDAyRvg8HDwuFgTFCtrZl72s7e2tnrpq3nF3g2/8WxZf3sQ0Mf0J28DbzIGSnPN+zRCOfbaKt0r79IXoUrzob0U+IQcDXzOWBftB3C7FmfLLHLnk7mlQ4Hb+lqJGX0lc8tt5jDz+7Q9CMqOQPqgP2+KMbKrYzcysYFCeNw343LM1OjKc6JZuXCfd0QagTj2TuiB+1B8NMZho4aQGYnZuNU1M12N1LkXgalIycqN512VaKoKzsbFhgcg4IoS85Lp6We4Mgfama8WJaargeO3edHKH/ru7+8vPADLht8JzEXNa2FDwnNQCPxvb8TJP+63Z+FnVHotGge//Uo4PrMXUoGS5di5JBtfx+XNGz6qwDzrNbUhsVxXg2YeYf8JdJtOp6M9E7UCyeExxm7AVxV75QeSuIsalTEO/TCnCgoWtWuB3O36OXbHYhlVJ3PmXFQKZLcaJJXMD91J0onkjQO2mBgUmt1bCwlj92J78c2IXMsYk3mCFHfUSNAC7xg4uQQLBK4biJyzeNjUYsU3m8062qB/u9YIHSEmtlXXuCn3Mj4MJJ87Vus1XiT80NzXLlpXr4c9EhDgbDbLrVu3RvkA9+0xVJRl48F6oHyY56KYM2vARh2QHSEZaGP+OD4+zltvvTUyzr7GxtfhBq5z+M6Jz6p0PF5+OxdhTyCZG9/65iDToK6JgdTBwcGodLjOi77u3LnT6Wkjb8XI2G0EGbvXrIaPaliNMEc19KyPdY95HJnCi7HCZjyMybxotJ7MveXaeObjx49H8uBDEre3t0cRhJOTk25oao5rUbsWyD0ZC5eV4DDM33W6yO0i9LCIGUESEAgLWD0AMy99+x5b31q+Vo0SY7bncJXyAsmgUBZtqoAO9jyMuNxc7cH39W9imqaVx+R1cOzPaNv3mK4Ou1SFsMg7g1ZONrOuwzD0vICfVRNtzBcjiaI3ijO65scxaxsCzz8ZHxFRXes6XhCzlYDdf3ZvovzdzJOslRVO5T/PzUiUcbt6xevHWlU07zEDFMxz1RPhOvporfVYPc/b2NhYeLIou4PtDTgk6rBppVH1rBetseXQ+sS8awPH/XidhH243+XQlhnWHr6stIJ/DMaqd1GPjfa9BpOEZZ1z8DgWtWuj3K9yM7BmbiYSDFZj8sMwdDSFoIByKfeCIaryTOaL5rLARQqqMlV9SYR/6ny5hrEhdBZGxtfa/HCxReVQZjCfCe06c8IVrnpZNB9CVhhVexMoOxS50XAtD2TsNgY2hp6Lkb89Np5rRV4RCzQ/OzvL48ePRx4YNLECWKSocIFRiM5L0I9pBH24pyqZRWjaddwoQitoK4A6ZrdavWL+hnbsZaieC3F6gxDG6M13XF9p5fE4FElfGKbZbHxcMTSrnmf1IDAS5quqxDDO0MJ5kUVjrvJkentOeLrc45yQkXn1RvCGvT6Mm/f3ejzJ/OAwXhBSAQbr4bUzeLtKX47o9MRvv06NBQHV2KqtrKz0XZ+g9Hfeeae7ShAHIlLmtrOzk9/6rd/K3bt3c3h4mP39/Z68ePHFF9Nay1tvvTXacelkGCVIW1tbl46eBWU4eXRwcNBdeYdXnDX3rkfCJyim/f39vPXWW/08Fy8e8yLuxtk6n//850dJLJQN2fxkzCAnJyf55Cc/mY2NjX58MNu7UY4wKWenbG1t5fDwMLu7u6OQDgqCcNedO3fyzd/8zb1CAcNjY/KFL3whs9msv+2J6pP19fW8+eabefToUT760Y/m9u3bGYYhv/mbv9lRPcLLfPwmpr29vY72PvWpT/VxHR4e9hdD1BjtG2+80aunhmHI7du3O0+RpCS+CR9SmYXX8PDhw7TW+lk1hGc2Njb6rurJ5PzMkiT51m/91rzwwgtZWVnJF7/4xdFbrfi9srLS5wOCtBJELpLkrbfe6ryEMmEODx8+7PyCoYKvPvWpT4022wFeKAbgTT/2xk5PTzviJrHH2qBsHj9+3Cs+Wmv54he/2N+a5s1AH/3oR/t1rAEKf2dnJx/5yEc6D1N7D204G4jcCtUstTwUD+Dhw4d9xyvhRjwKrkcHra2t5fbt27l161aeffbZ3LlzJ+vr6/nkJz/Zwzh+P/EwnO+PQJ6smNEZ3/AN37DwlFMM7+PHj3P37t0uR7xACFC7u7ub5LxQ47Of/WzOzs6yt7c3AlpXtWsRc0/msV67xE6g8X1r43c9OqaejBMmCFIyd6udZWYLsDPgjhXaWtJcBpmMY18OZRgVOYTAd44D8nwQC/3SjCws6Ddv3hz1zZhd9WLXdDqd5u7dux3BM2aPid8wPnR1DNIhK8ZDuaURbo2HcgATCN8I6Pbt20nOSy9ZnxdffHG0wcnoxuEOH7CGckNYmWf1NHZ3d0fJPnjDdLMHwPfQ2GvBeLjOPIJCSJI333yzx/pRLo7bI7B21Y04GRtzRBFAR6Nu+qznzkyn07z++uujhCLfUevv8bumG+DlGLK9W9efTyaTPP/88yOZAgk7OV89yJOTk/7GKgxIzX+ZFuYxflydtrW11QGUvYQq1zTowiF+k8n56yHrjmHLDrLhMlHm+vbbb494qno7XMeYMaA1JHR2dpaXXnpptL6Lxu92bTYx/eAP/mCSuXWzi1Xjc3XM6+vr2dvb68xVr7dr591tJGhgYrvhKPbKgHxmobfidkmWz9wAEVvZ8Zv50qxU+A6PBM/AjG13jfAGSMDupf92rBVBssfAnKjBx0gxPp9PYjpb6SVzpsWAodj9nQ1WTYbSqoKz0SfZVOfl33bXvfZuNsaVvvDZop2TyTyRDj9QAlhzRczRm1qsnPEcrHyq+23+4bAt86ONDM2gxa49fzMH1of1svLkfp5PGMbK1fJL/35eMn9dnuWLa8yDphX3UTLMmFHG8KgbfVbFXA2n+ddrCFhApup6EUo1fU0b/rfeMk/Z+zeQta6yYauJ9dls9rU/OOy9bF5sFppCf5qPwkzSqzpAKyg/PnN/JHQgLEwHsRAIhNMKOBkrD5QfQjaZTHrtOdZ8fX29h0uqW8YYCC/4x8gUJEW8kuezMSqZb7OeTCajnEKtWAGRcI8rhegXgdre3u6HtDEm3GFvICFJ5+MQeL6T3ZRlYkxgZFctnZycdANM5YC9KBrjhj72TIyQKm8xZiPmJP0FEt7Q4zVjTqb91tZWkvEmFebFhhfGD13ZrEJ4y0rB3im8uQihVWMKLRzSRA487tbmp19WAzsMQ3f3HYqqnoPlEDmDRi5ZZjw+OIvv2Zjm8GWVK8/JxowxJ+khPRt3rxEyQX7E3pdBGv0TWqXSCAXs8mYbMPMGvMA47Tl5EyR9MC82ejE36zX3xTPQLT5u5Kp2bcIyi5AsC0wJHwLAYVagNsIzdslqIhRExo45FGE9OwLGRLgdorAVtiCjxIgR+nPcVZ7H/DzmZFzZ4jgr16IwOGKhtdbfHl+9CN/r17iB/B3WwgghSCAg0I7RezI/MsHhAJjPLr09HmjnTUlG3iSUnJCz0na4AlqwyxJXFmX04osvjtar8oE9BSsmtqjzvXc811Ac7jJzNx251pUOVrgo4MePH49OOTRfOAfCff7eiJPPFyniOm7zKdfb00LZIm+M1c+xkiXvYSVnT9vxect5PTsfw23volb7WD4t61xv3jDS53vLu5/jvjlllVAOa01/8JGT7ZRbV4+Y5jCwnwfteLE8tK7eh9cRvUf+oHqetV0L5G6l6fgjBHR5WzIuY7KQJeP6XicTYebT09Meb7UhqRs4WDRvXebZjJl+aV48ewokmNzHbDbrSWAUG1a5uuEoVo4xcNWB4+suo7M3YqVF8tkNhiLxBR1sPKArZ8P4QCzowYstTAO+G4ahJwi9McxGifmwljbitfTR+wnw0HCfvSYWOmhTjaaVPGOze7xI8JjH2dlZF26HUvwcaAGa9j2VhvCtd7C6VfffCtAeGIlMr0WlcQ0ZoLQcNlqkbKzomSvIt4Zl+F1DLlzjv+21+LmeB+tpI++XVnidTH+vh5G1r0M+uB/P2LX79hiNthmDjbBlj++sNxaBDbd6TDEGwRsFn9SuBXJnkhZ0IzsrsGR8JrOZwCgR5ME1EBDhNWrBHbehILmUjDeOWDEwJp5bfwhnVFRl1MF8eK4VDdd7W763c/soBaNN6IhSIszB3yhs6FJdfxA+mygc5nDs3MjJ4a6qUPh/e3t7dJY8c6PCBAa2EalbrG2QnZijWmhvb68bOZ7te1gHvnPstq6P15L7GQNrS8KrGjV4pvIKqJgXm1caORxRPRwrIa+Xw0w8h2RyTZxyrfMdAJHj4+PR+eIYr0p7aLq6utp5JcmlMCYyhwwyN852MsqF5jzTXiA0rEaB60xj84PnzPiNnOuaWbYIbxKzr+FNfvPcapCqIfGz8ZKs7xbRF28VPtnc3MzJycnonKontWuB3K9qtvi2gjBAjZt6oWqsjL/91nsjwfpaNuKDNS5fQw4OyzAGL6YTQnXBHz58OEKWbH2uiC6Z19LaPaNkLRmf244RcokZ/3tjF7SCPszbngRut2PpniuNChBXAdEPnhc7HzFU0Nrnf1AmmWTkRVQBsOBTYYA3hMGwsFUjbEPeWuveDEbRSWqvt9fX59XQ/6JwjREe6NCvEDRfMDfPlf48D2TCCNGK1crNckFYzmjSNK7IEhraK/Daetzsr8Dg1V2yfA5oAGjwHPgEIwB/MAd7uQ6bWEaguT0VvrOeQDarjHEInD2OmzdvXnqu6elx+lnQunr7Xp/Dw8NeaeY5JunVZawHx0RjbJ4WlrkWyJ1WLREErZlwl6whRGZul1y5lCvJKHbLM0B9VahqmIVrqzuZzLduOxFrxV/nBpNbKVSEaKGnH9fRQxsafdkl5l6utSJa5DbzPHsDdkU9rircFenSP3sGCEfYUEBTGNto3WEnI/Xq4fGKNSvkRYjPsXjvJF2Ejm28GWvlB9PAcXXzb/2ftTbarp7fIqRZjX1F3vX7RfFbaG2UucizSeaGtVbDmNf8bMa0iEaVFii/RWg4GcepLZMes3UAnzlnxf8GPfbkPC83K3znPhh/LQOtOgM6wVsksGvjep+3ZD5I0kM9lmGHST8QyN2D9CLR/LKMZL65ye4ZLwBI5oxNos5Ii1in0bTdJIeEnFnnWRY8LwqImGQt3znOa2bHzfKmGM6Wr4vMOEE60OfWrVsj44XAeWduDWk5FgsNEQBccxQwY7PQ4AqzyceM59yIBQoDdPPmzY5yjMhcznZ0dNRRLcbPioT7nDPxaZoPHz4ceRrmCdbPhoF+edk1Hh+G0AbFHtXq6urorU9WGkl6tYyR5HQ67ZuBfOSwY9Ge71WhAPOhhdxGrRoWaEDM1gq78jX8C29c1Wq4scbMQa6MD0SMcaOChbHVJG8FUsm8lLkaHW/o8T3wMjqkGhgbIvIoyA90efTo0ciIG+i4jBEeZC6ttdHZNvYCkVuKGBiX/7Yn01rriWh+nlYtcy3q3FtrbyXZz/lLtz8I7bl8cMaafLDG+0Eaa7Ic73vZPkhjTd6f8X7jMAzPL/riWij3JGmtfWa4ohj/urUP0liTD9Z4P0hjTZbjfS/bB2msyfUb77UIyyzbsi3bsi3b17YtlfuyLduyLduHsF0n5f5T7/cAfhftgzTW5IM13g/SWJPleN/L9kEaa3LNxnttYu7LtmzLtmzL9rVr1wm5L9uyLduyLdvXqL3vyr219t2ttc+11r7QWvvh93s8SdJa+yuttbuttV/TZ8+01n6ptfb5i9939N2PXIz/c621P/p1HuvHWmv/V2vtN1trv95a+4+u63hba5uttV9urf3qxVh/7LqOtYx7pbX2j1trv3Ddx9ta+1Jr7Z+21j7bWvvMdR5va+12a+2vt9b+2QX//v5rPNbfe0FTfh611v70dR1vkvFmnK/3T5KVJP88ySeSrCf51SSffD/HdDGuP5jk25P8mj77i0l++OLvH07yn1/8/cmLcW8k+fjFfFa+jmN9Ocm3X/x9I8lvXYzp2o03SUuye/H3WpL/N8m/cR3HWsb9Hyf5n5P8wnXmhYsxfCnJc+WzazneJD+d5D+8+Hs9ye3rOtYy7pUkbyT5xus83q87YQqRfn+Sv63/fyTJj7yfY9JYvilj5f65JC9f/P1yks8tGnOSv53k97+P4/6bSb7ruo83yXaSf5TkX7/OY03y0SR/N8kfknK/zuNdpNyv3XiT3EzyL3KR97vOY10w9j+S5P+57uN9v8MyH0nyO/r/1YvPrmN7cRiG15Pk4vcLF59fmzm01r4pye/LOSK+luO9CHF8NsndJL80DMO1HetF+6+S/CdJfFDLdR7vkOTvtNZ+pbX26YvPruN4P5HkrST//UXI679rre1c07HW9n1Jfubi72s73vdbuS86+eaDVr5zLebQWttN8nNJ/vQwDI+edOmCz75u4x2G4WwYhm/LOSL+jtbap55w+fs61tbav5Pk7jAMv/Jub1nw2debF/7AMAzfnuR7kvxQa+0PPuHa93O8qzkPff43wzD8vpwfP/KknNt1oG1aa+tJ/niS/+Vply747Os63vdbub+a5GP6/6NJXnufxvK09mZr7eUkufh99+Lz930OrbW1nCv2/2kYhv/14uNrO94kGYbhQZK/l+S7c33H+geS/PHW2peS/GySP9Ra+6u5vuPNMAyvXfy+m+RvJPmOXM/xvprk1QvPLUn+es6V/XUcq9v3JPlHwzC8efH/tR3v+63c/2GSb2mtffzCIn5fkp9/n8d0Vfv5JN9/8ff35zy2zeff11rbaK19PMm3JPnlr9egWmstyV9O8pvDMPwX13m8rbXnW2u3L/7eSvJvJ/ln13GsSTIMw48Mw/DRYRi+Kee8+X8Ow/DvX9fxttZ2Wms3+DvnseFfu47jHYbhjSS/01r7vRcf/eEkv3Edx1ran8g8JMO4rud434+ERElO/LGcV3j88yR/9v0ez8WYfibJ60lOc26B/2SSZ3OeWPv8xe9ndP2fvRj/55J8z9d5rP9mzt29f5Lksxc/f+w6jjfJv5zkH1+M9deS/KcXn1+7sS4Y+3dmnlC9luPNeRz7Vy9+fh15usbj/bYkn7ngh/8tyZ3rOtaL528neTvJLX12bce73KG6bMu2bMv2IWzvd1hm2ZZt2ZZt2d6DtlTuy7Zsy7ZsH8K2VO7LtmzLtmwfwrZU7su2bMu2bB/CtlTuy7Zsy7ZsH8K2VO7LtmzLtmwfwrZU7su2bMu2bB/CtlTuy7Zsy7ZsH8L2/wOGoK3djyA/DQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0]-X[1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34359336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(resize_image((X[0]-X[326])[0], desired_size=20)[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ec8ae",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce434ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_probability = 1.0\n",
    "def permutate_and_random_cutout(input_img):\n",
    "    img = input_img.copy()\n",
    "    if random.random() < permutation_probability:\n",
    "        img = np.random.permutation(input_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa02dcef",
   "metadata": {},
   "source": [
    "Inputs need to have 3 channels for ImageDataGenerator to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c215a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_shape = (3,1)\n",
    "def CBN(model,filters,ishape=0):\n",
    "    if (ishape!=0):\n",
    "        model.add(Conv2D(filters, filter_shape, padding='same',\n",
    "                         input_shape=ishape))\n",
    "    else:\n",
    "        model.add(Conv2D(filters, filter_shape, padding='same'))\n",
    "\n",
    "    #model.add(Conv2D(filters/2, filter_shape, padding='same'))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(GaussianNoise(0.3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1513ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 1e-5\n",
    "min_lr = 1e-8\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34b0003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD()\n",
    "adam = Adam()\n",
    "rmsprop = RMSprop()\n",
    "\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9aaf4b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=5, min_lr=min_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cde2c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model=CBN(model,32,input_shape)\n",
    "    model=CBN(model,64)\n",
    "    model=CBN(model,128)\n",
    "    model=CBN(model,256)\n",
    "    model=CBN(model,512)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    # checkpoint = ModelCheckpoint('best_model.h5', monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dfb1028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_3_channels_np(a):\n",
    "    #a = [resize_image(x) for x in a]\n",
    "    a = [np.repeat(x.reshape(x.shape[0], x.shape[1], 1), 3, axis=2) for x in a]\n",
    "    a = np.array(a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4208f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    samplewise_center=True,\n",
    "    #horizontal_flip = True,\n",
    "    preprocessing_function=permutate_and_random_cutout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "008d8f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "X_train = to_3_channels_np(X_train)\n",
    "X_test = to_3_channels_np(X_test)\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f02d64a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 768, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "669614f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "210d2fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 768, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ffa3e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 13:55:39.115340: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-05-21 13:55:39.115864: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-05-21 13:55:39.182854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 13:55:39.183067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:26:00.0 name: NVIDIA GeForce RTX 2070 SUPER computeCapability: 7.5\n",
      "coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2022-05-21 13:55:39.183089: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-05-21 13:55:39.184500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-05-21 13:55:39.184546: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-05-21 13:55:39.185948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-21 13:55:39.186206: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-21 13:55:39.187515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-05-21 13:55:39.188263: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-05-21 13:55:39.191138: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-05-21 13:55:39.191291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 13:55:39.191593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 13:55:39.191751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-05-21 13:55:39.192070: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 13:55:39.192626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 13:55:39.192804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:26:00.0 name: NVIDIA GeForce RTX 2070 SUPER computeCapability: 7.5\n",
      "coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2022-05-21 13:55:39.192826: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-05-21 13:55:39.192849: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-05-21 13:55:39.192867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-05-21 13:55:39.192883: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-21 13:55:39.192898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-21 13:55:39.192915: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-05-21 13:55:39.192931: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-05-21 13:55:39.192946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-05-21 13:55:39.193018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 13:55:39.193236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 13:55:39.193386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-05-21 13:55:39.193418: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-05-21 13:55:39.515604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-05-21 13:55:39.515631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-05-21 13:55:39.515636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-05-21 13:55:39.515856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 13:55:39.516036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 13:55:39.516179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 13:55:39.516301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6776 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:26:00.0, compute capability: 7.5)\n",
      "2022-05-21 13:55:39.516469: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 200, 768, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 200, 768, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 200, 768, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 100, 384, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 100, 384, 64)      6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100, 384, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100, 384, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 192, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 192, 128)      24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50, 192, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50, 192, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 96, 256)       98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 25, 96, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 25, 96, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 48, 512)       393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 48, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 48, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 24, 512)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               18874624  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 19,534,722\n",
      "Trainable params: 19,532,738\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 13:55:39.848801: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-05-21 13:55:39.864823: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3601025000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 13:55:40.287855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-05-21 13:55:40.414864: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 5s 11ms/step - loss: 17.7210 - accuracy: 0.4964 - val_loss: 0.6488 - val_accuracy: 0.6190\n",
      "Epoch 2/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.8039 - accuracy: 0.5725 - val_loss: 0.7321 - val_accuracy: 0.5714\n",
      "Epoch 3/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.8094 - accuracy: 0.5490 - val_loss: 0.6296 - val_accuracy: 0.6667\n",
      "Epoch 4/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.8080 - accuracy: 0.5912 - val_loss: 0.6416 - val_accuracy: 0.6429\n",
      "Epoch 5/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6387 - accuracy: 0.5630 - val_loss: 0.6697 - val_accuracy: 0.5952\n",
      "Epoch 6/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 1.0700 - accuracy: 0.5220 - val_loss: 46.0500 - val_accuracy: 0.4286\n",
      "Epoch 7/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6390 - accuracy: 0.5944 - val_loss: 0.6814 - val_accuracy: 0.5952\n",
      "Epoch 8/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6940 - accuracy: 0.4957 - val_loss: 0.6765 - val_accuracy: 0.4524\n",
      "Epoch 9/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6398 - accuracy: 0.5512 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 10/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6400 - accuracy: 0.5810 - val_loss: 0.6506 - val_accuracy: 0.6429\n",
      "Epoch 11/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6487 - accuracy: 0.5961 - val_loss: 0.6473 - val_accuracy: 0.6429\n",
      "Epoch 12/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6425 - accuracy: 0.5676 - val_loss: 0.6467 - val_accuracy: 0.6429\n",
      "Epoch 13/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6511 - accuracy: 0.5084 - val_loss: 0.6467 - val_accuracy: 0.6429\n",
      "Epoch 14/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6394 - accuracy: 0.5745 - val_loss: 0.6458 - val_accuracy: 0.6429\n",
      "Epoch 15/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6362 - accuracy: 0.5779 - val_loss: 0.6461 - val_accuracy: 0.6429\n",
      "Epoch 16/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6333 - accuracy: 0.5914 - val_loss: 0.6457 - val_accuracy: 0.6429\n",
      "Epoch 17/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6315 - accuracy: 0.5607 - val_loss: 0.6458 - val_accuracy: 0.6429\n",
      "Epoch 18/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6353 - accuracy: 0.6042 - val_loss: 0.6460 - val_accuracy: 0.6429\n",
      "Epoch 19/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6349 - accuracy: 0.5712 - val_loss: 0.6462 - val_accuracy: 0.6429\n",
      "Epoch 20/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6440 - accuracy: 0.5468 - val_loss: 0.6453 - val_accuracy: 0.6429\n",
      "Epoch 21/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6320 - accuracy: 0.5807 - val_loss: 0.6450 - val_accuracy: 0.6429\n",
      "Epoch 22/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6193 - accuracy: 0.5795 - val_loss: 0.6439 - val_accuracy: 0.6429\n",
      "Epoch 23/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6606 - accuracy: 0.5264 - val_loss: 0.6462 - val_accuracy: 0.6429\n",
      "Epoch 24/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6403 - accuracy: 0.5602 - val_loss: 0.6436 - val_accuracy: 0.6429\n",
      "Epoch 25/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6459 - accuracy: 0.5660 - val_loss: 0.6456 - val_accuracy: 0.6429\n",
      "Epoch 26/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6545 - accuracy: 0.5893 - val_loss: 0.6434 - val_accuracy: 0.6429\n",
      "Epoch 27/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6214 - accuracy: 0.5791 - val_loss: 0.6447 - val_accuracy: 0.6429\n",
      "Epoch 28/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6453 - accuracy: 0.5851 - val_loss: 0.6442 - val_accuracy: 0.6429\n",
      "Epoch 29/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6354 - accuracy: 0.5661 - val_loss: 0.6441 - val_accuracy: 0.6429\n",
      "Epoch 30/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6407 - accuracy: 0.5651 - val_loss: 0.6463 - val_accuracy: 0.6429\n",
      "Epoch 31/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6485 - accuracy: 0.5905 - val_loss: 0.6450 - val_accuracy: 0.6429\n",
      "Epoch 32/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6489 - accuracy: 0.5405 - val_loss: 0.6455 - val_accuracy: 0.6429\n",
      "Epoch 33/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6498 - accuracy: 0.5923 - val_loss: 0.6439 - val_accuracy: 0.6429\n",
      "Epoch 34/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6423 - accuracy: 0.5355 - val_loss: 0.6449 - val_accuracy: 0.6429\n",
      "Epoch 35/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6485 - accuracy: 0.5426 - val_loss: 0.6455 - val_accuracy: 0.6429\n",
      "Epoch 36/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6420 - accuracy: 0.5526 - val_loss: 0.6453 - val_accuracy: 0.6429\n",
      "Epoch 37/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6498 - accuracy: 0.5186 - val_loss: 0.6460 - val_accuracy: 0.6429\n",
      "Epoch 38/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6499 - accuracy: 0.5250 - val_loss: 0.6455 - val_accuracy: 0.6429\n",
      "Epoch 39/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6384 - accuracy: 0.5654 - val_loss: 0.6451 - val_accuracy: 0.6429\n",
      "Epoch 40/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6362 - accuracy: 0.5639 - val_loss: 0.6462 - val_accuracy: 0.6429\n",
      "Epoch 41/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6418 - accuracy: 0.6063 - val_loss: 0.6452 - val_accuracy: 0.6429\n",
      "Epoch 42/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6439 - accuracy: 0.5460 - val_loss: 0.6452 - val_accuracy: 0.6429\n",
      "Epoch 43/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6469 - accuracy: 0.5562 - val_loss: 0.6460 - val_accuracy: 0.6429\n",
      "Epoch 44/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6641 - accuracy: 0.5389 - val_loss: 0.6458 - val_accuracy: 0.6429\n",
      "Epoch 45/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6411 - accuracy: 0.6038 - val_loss: 0.6446 - val_accuracy: 0.6429\n",
      "Epoch 46/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6174 - accuracy: 0.5750 - val_loss: 0.6436 - val_accuracy: 0.6429\n",
      "Epoch 47/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6286 - accuracy: 0.5691 - val_loss: 0.6447 - val_accuracy: 0.6429\n",
      "Epoch 48/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6516 - accuracy: 0.5373 - val_loss: 0.6447 - val_accuracy: 0.6429\n",
      "Epoch 49/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6476 - accuracy: 0.5435 - val_loss: 0.6449 - val_accuracy: 0.6429\n",
      "Epoch 50/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6559 - accuracy: 0.5288 - val_loss: 0.6452 - val_accuracy: 0.6429\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6452 - accuracy: 0.6429\n"
     ]
    }
   ],
   "source": [
    "model = build_model(X_train.shape[1:])\n",
    "\n",
    "history=model.fit(X_train, y_train,\n",
    "                  steps_per_epoch=len(X_train) / BATCH_SIZE, \n",
    "                  epochs=EPOCHS,\n",
    "                  validation_data=(X_test, y_test),\n",
    "                  callbacks=[reduce_lr],\n",
    "                  verbose=1)\n",
    "\n",
    "## TEST\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2492a25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6452401280403137, 0.6428571343421936]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca442a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/10\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 200, 768, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 200, 768, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 200, 768, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 100, 384, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 100, 384, 64)      6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100, 384, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 100, 384, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 50, 192, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 50, 192, 128)      24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 50, 192, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 50, 192, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 25, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 96, 256)       98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 25, 96, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 25, 96, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 12, 48, 512)       393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 12, 48, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 12, 48, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 24, 512)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               18874624  \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 19,534,722\n",
      "Trainable params: 19,532,738\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.7743 - accuracy: 0.4628 - val_loss: 0.7520 - val_accuracy: 0.4762\n",
      "Epoch 2/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7186 - accuracy: 0.5129 - val_loss: 0.7484 - val_accuracy: 0.4048\n",
      "Epoch 3/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7412 - accuracy: 0.4532 - val_loss: 0.7392 - val_accuracy: 0.4524\n",
      "Epoch 4/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6853 - accuracy: 0.5724 - val_loss: 0.7387 - val_accuracy: 0.5238\n",
      "Epoch 5/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7028 - accuracy: 0.5413 - val_loss: 0.7339 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7349 - accuracy: 0.4716 - val_loss: 0.7328 - val_accuracy: 0.5476\n",
      "Epoch 7/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6881 - accuracy: 0.5705 - val_loss: 0.7300 - val_accuracy: 0.5238\n",
      "Epoch 8/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6901 - accuracy: 0.5794 - val_loss: 0.7261 - val_accuracy: 0.5476\n",
      "Epoch 9/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6996 - accuracy: 0.5516 - val_loss: 0.7232 - val_accuracy: 0.5476\n",
      "Epoch 10/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6849 - accuracy: 0.5404 - val_loss: 0.7202 - val_accuracy: 0.5476\n",
      "Epoch 11/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6829 - accuracy: 0.5609 - val_loss: 0.7187 - val_accuracy: 0.5476\n",
      "Epoch 12/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6735 - accuracy: 0.5637 - val_loss: 0.7153 - val_accuracy: 0.5476\n",
      "Epoch 13/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7181 - accuracy: 0.5185 - val_loss: 0.7129 - val_accuracy: 0.5476\n",
      "Epoch 14/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6773 - accuracy: 0.5846 - val_loss: 0.7094 - val_accuracy: 0.5476\n",
      "Epoch 15/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6997 - accuracy: 0.5466 - val_loss: 0.7069 - val_accuracy: 0.5476\n",
      "Epoch 16/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6834 - accuracy: 0.5364 - val_loss: 0.7048 - val_accuracy: 0.5476\n",
      "Epoch 17/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7021 - accuracy: 0.5635 - val_loss: 0.7024 - val_accuracy: 0.5476\n",
      "Epoch 18/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7426 - accuracy: 0.4650 - val_loss: 0.6982 - val_accuracy: 0.5476\n",
      "Epoch 19/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6529 - accuracy: 0.6350 - val_loss: 0.6965 - val_accuracy: 0.5476\n",
      "Epoch 20/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6797 - accuracy: 0.5846 - val_loss: 0.6913 - val_accuracy: 0.5714\n",
      "Epoch 21/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6615 - accuracy: 0.6040 - val_loss: 0.6896 - val_accuracy: 0.5476\n",
      "Epoch 22/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6892 - accuracy: 0.5756 - val_loss: 0.6862 - val_accuracy: 0.5476\n",
      "Epoch 23/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6813 - accuracy: 0.5570 - val_loss: 0.6848 - val_accuracy: 0.5476\n",
      "Epoch 24/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6755 - accuracy: 0.5900 - val_loss: 0.6797 - val_accuracy: 0.5714\n",
      "Epoch 25/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6749 - accuracy: 0.6193 - val_loss: 0.6778 - val_accuracy: 0.5714\n",
      "Epoch 26/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6786 - accuracy: 0.6127 - val_loss: 0.6741 - val_accuracy: 0.5714\n",
      "Epoch 27/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6520 - accuracy: 0.6464 - val_loss: 0.6723 - val_accuracy: 0.5714\n",
      "Epoch 28/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6762 - accuracy: 0.5566 - val_loss: 0.6695 - val_accuracy: 0.5714\n",
      "Epoch 29/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6470 - accuracy: 0.5858 - val_loss: 0.6687 - val_accuracy: 0.5714\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6067 - accuracy: 0.6655 - val_loss: 0.6648 - val_accuracy: 0.5714\n",
      "Epoch 31/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6589 - accuracy: 0.6058 - val_loss: 0.6620 - val_accuracy: 0.5714\n",
      "Epoch 32/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6656 - accuracy: 0.6209 - val_loss: 0.6608 - val_accuracy: 0.5952\n",
      "Epoch 33/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6475 - accuracy: 0.5807 - val_loss: 0.6584 - val_accuracy: 0.5714\n",
      "Epoch 34/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6513 - accuracy: 0.5941 - val_loss: 0.6581 - val_accuracy: 0.5714\n",
      "Epoch 35/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6261 - accuracy: 0.6306 - val_loss: 0.6548 - val_accuracy: 0.5714\n",
      "Epoch 36/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6464 - accuracy: 0.6203 - val_loss: 0.6543 - val_accuracy: 0.5714\n",
      "Epoch 37/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6784 - accuracy: 0.5720 - val_loss: 0.6512 - val_accuracy: 0.5714\n",
      "Epoch 38/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6570 - accuracy: 0.6426 - val_loss: 0.6486 - val_accuracy: 0.5714\n",
      "Epoch 39/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6163 - accuracy: 0.6598 - val_loss: 0.6462 - val_accuracy: 0.5952\n",
      "Epoch 40/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6525 - accuracy: 0.5856 - val_loss: 0.6441 - val_accuracy: 0.5952\n",
      "Epoch 41/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6203 - accuracy: 0.6147 - val_loss: 0.6408 - val_accuracy: 0.5952\n",
      "Epoch 42/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6421 - accuracy: 0.6167 - val_loss: 0.6384 - val_accuracy: 0.6190\n",
      "Epoch 43/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6762 - accuracy: 0.5788 - val_loss: 0.6380 - val_accuracy: 0.6190\n",
      "Epoch 44/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6279 - accuracy: 0.6359 - val_loss: 0.6343 - val_accuracy: 0.6190\n",
      "Epoch 45/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6541 - accuracy: 0.5923 - val_loss: 0.6327 - val_accuracy: 0.6429\n",
      "Epoch 46/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6382 - accuracy: 0.6444 - val_loss: 0.6306 - val_accuracy: 0.6429\n",
      "Epoch 47/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6265 - accuracy: 0.6428 - val_loss: 0.6314 - val_accuracy: 0.6190\n",
      "Epoch 48/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6599 - accuracy: 0.5883 - val_loss: 0.6302 - val_accuracy: 0.6190\n",
      "Epoch 49/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6193 - accuracy: 0.6671 - val_loss: 0.6265 - val_accuracy: 0.6429\n",
      "Epoch 50/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6509 - accuracy: 0.5930 - val_loss: 0.6238 - val_accuracy: 0.6429\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6238 - accuracy: 0.6429\n",
      "Training fold 2/10\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 200, 768, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 200, 768, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 200, 768, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 100, 384, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 100, 384, 64)      6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 100, 384, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 100, 384, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 50, 192, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 50, 192, 128)      24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 50, 192, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 50, 192, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 25, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 25, 96, 256)       98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 25, 96, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 25, 96, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 12, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 12, 48, 512)       393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 12, 48, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 12, 48, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 6, 24, 512)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               18874624  \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 19,534,722\n",
      "Trainable params: 19,532,738\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.7640 - accuracy: 0.5517 - val_loss: 0.9495 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.7509 - accuracy: 0.5427 - val_loss: 0.8541 - val_accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6943 - accuracy: 0.5849 - val_loss: 0.8420 - val_accuracy: 0.3571\n",
      "Epoch 4/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.7149 - accuracy: 0.4951 - val_loss: 0.8415 - val_accuracy: 0.3810\n",
      "Epoch 5/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6974 - accuracy: 0.5132 - val_loss: 0.8435 - val_accuracy: 0.4286\n",
      "Epoch 6/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.7150 - accuracy: 0.5451 - val_loss: 0.8411 - val_accuracy: 0.3571\n",
      "Epoch 7/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6793 - accuracy: 0.5885 - val_loss: 0.8379 - val_accuracy: 0.4286\n",
      "Epoch 8/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.7025 - accuracy: 0.5263 - val_loss: 0.8385 - val_accuracy: 0.4286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.7189 - accuracy: 0.5293 - val_loss: 0.8374 - val_accuracy: 0.4286\n",
      "Epoch 10/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6922 - accuracy: 0.5409 - val_loss: 0.8332 - val_accuracy: 0.4048\n",
      "Epoch 11/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7383 - accuracy: 0.5184 - val_loss: 0.8310 - val_accuracy: 0.4048\n",
      "Epoch 12/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7063 - accuracy: 0.5494 - val_loss: 0.8277 - val_accuracy: 0.4048\n",
      "Epoch 13/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7255 - accuracy: 0.4935 - val_loss: 0.8274 - val_accuracy: 0.4048\n",
      "Epoch 14/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6932 - accuracy: 0.5327 - val_loss: 0.8277 - val_accuracy: 0.4048\n",
      "Epoch 15/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7343 - accuracy: 0.4886 - val_loss: 0.8269 - val_accuracy: 0.4048\n",
      "Epoch 16/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.7191 - accuracy: 0.5234 - val_loss: 0.8233 - val_accuracy: 0.4048\n",
      "Epoch 17/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.7217 - accuracy: 0.5263 - val_loss: 0.8242 - val_accuracy: 0.4048\n",
      "Epoch 18/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6647 - accuracy: 0.5606 - val_loss: 0.8217 - val_accuracy: 0.4048\n",
      "Epoch 19/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7014 - accuracy: 0.5604 - val_loss: 0.8218 - val_accuracy: 0.4048\n",
      "Epoch 20/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7018 - accuracy: 0.5520 - val_loss: 0.8184 - val_accuracy: 0.4048\n",
      "Epoch 21/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6951 - accuracy: 0.5329 - val_loss: 0.8201 - val_accuracy: 0.4048\n",
      "Epoch 22/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6926 - accuracy: 0.5450 - val_loss: 0.8171 - val_accuracy: 0.4048\n",
      "Epoch 23/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6431 - accuracy: 0.5888 - val_loss: 0.8155 - val_accuracy: 0.4048\n",
      "Epoch 24/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6736 - accuracy: 0.5805 - val_loss: 0.8126 - val_accuracy: 0.4048\n",
      "Epoch 25/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6609 - accuracy: 0.5694 - val_loss: 0.8100 - val_accuracy: 0.4048\n",
      "Epoch 26/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6940 - accuracy: 0.5406 - val_loss: 0.8117 - val_accuracy: 0.4048\n",
      "Epoch 27/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6852 - accuracy: 0.5596 - val_loss: 0.8085 - val_accuracy: 0.4048\n",
      "Epoch 28/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6603 - accuracy: 0.6251 - val_loss: 0.8090 - val_accuracy: 0.3810\n",
      "Epoch 29/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6715 - accuracy: 0.5605 - val_loss: 0.8093 - val_accuracy: 0.3810\n",
      "Epoch 30/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6885 - accuracy: 0.5593 - val_loss: 0.8063 - val_accuracy: 0.3810\n",
      "Epoch 31/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6741 - accuracy: 0.5747 - val_loss: 0.8048 - val_accuracy: 0.4048\n",
      "Epoch 32/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6715 - accuracy: 0.5868 - val_loss: 0.8045 - val_accuracy: 0.4048\n",
      "Epoch 33/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6340 - accuracy: 0.6522 - val_loss: 0.8040 - val_accuracy: 0.4048\n",
      "Epoch 34/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6545 - accuracy: 0.6384 - val_loss: 0.8056 - val_accuracy: 0.4048\n",
      "Epoch 35/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6572 - accuracy: 0.6271 - val_loss: 0.8028 - val_accuracy: 0.4048\n",
      "Epoch 36/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6534 - accuracy: 0.6004 - val_loss: 0.7998 - val_accuracy: 0.3810\n",
      "Epoch 37/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6748 - accuracy: 0.5411 - val_loss: 0.7984 - val_accuracy: 0.4048\n",
      "Epoch 38/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6619 - accuracy: 0.5981 - val_loss: 0.8003 - val_accuracy: 0.3810\n",
      "Epoch 39/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6357 - accuracy: 0.6895 - val_loss: 0.7958 - val_accuracy: 0.4048\n",
      "Epoch 40/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6828 - accuracy: 0.5219 - val_loss: 0.7963 - val_accuracy: 0.4048\n",
      "Epoch 41/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6416 - accuracy: 0.6226 - val_loss: 0.7970 - val_accuracy: 0.3810\n",
      "Epoch 42/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6695 - accuracy: 0.5355 - val_loss: 0.7939 - val_accuracy: 0.4048\n",
      "Epoch 43/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6546 - accuracy: 0.6175 - val_loss: 0.7979 - val_accuracy: 0.4048\n",
      "Epoch 44/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6516 - accuracy: 0.5898 - val_loss: 0.7942 - val_accuracy: 0.4048\n",
      "Epoch 45/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6353 - accuracy: 0.6332 - val_loss: 0.7916 - val_accuracy: 0.4286\n",
      "Epoch 46/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6241 - accuracy: 0.6398 - val_loss: 0.7907 - val_accuracy: 0.4286\n",
      "Epoch 47/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6449 - accuracy: 0.5975 - val_loss: 0.7909 - val_accuracy: 0.4286\n",
      "Epoch 48/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6556 - accuracy: 0.6250 - val_loss: 0.7897 - val_accuracy: 0.4048\n",
      "Epoch 49/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6198 - accuracy: 0.6819 - val_loss: 0.7886 - val_accuracy: 0.4286\n",
      "Epoch 50/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6396 - accuracy: 0.6229 - val_loss: 0.7871 - val_accuracy: 0.4286\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.7871 - accuracy: 0.4286\n",
      "Training fold 3/10\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 200, 768, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 200, 768, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 200, 768, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 100, 384, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 100, 384, 64)      6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 100, 384, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 100, 384, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 50, 192, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 50, 192, 128)      24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 50, 192, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 50, 192, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 25, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 25, 96, 256)       98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 25, 96, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 25, 96, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 12, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 12, 48, 512)       393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 12, 48, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 12, 48, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 6, 24, 512)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               18874624  \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 19,534,722\n",
      "Trainable params: 19,532,738\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6958 - accuracy: 0.5702 - val_loss: 0.7222 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7215 - accuracy: 0.5073 - val_loss: 0.6894 - val_accuracy: 0.5952\n",
      "Epoch 3/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7271 - accuracy: 0.5197 - val_loss: 0.6846 - val_accuracy: 0.5952\n",
      "Epoch 4/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6667 - accuracy: 0.5973 - val_loss: 0.6823 - val_accuracy: 0.5952\n",
      "Epoch 5/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7065 - accuracy: 0.5738 - val_loss: 0.6793 - val_accuracy: 0.5952\n",
      "Epoch 6/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7035 - accuracy: 0.5615 - val_loss: 0.6758 - val_accuracy: 0.5952\n",
      "Epoch 7/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6873 - accuracy: 0.5724 - val_loss: 0.6718 - val_accuracy: 0.6190\n",
      "Epoch 8/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6589 - accuracy: 0.5562 - val_loss: 0.6689 - val_accuracy: 0.6190\n",
      "Epoch 9/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7046 - accuracy: 0.5416 - val_loss: 0.6646 - val_accuracy: 0.6667\n",
      "Epoch 10/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6946 - accuracy: 0.5587 - val_loss: 0.6650 - val_accuracy: 0.6429\n",
      "Epoch 11/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6869 - accuracy: 0.5735 - val_loss: 0.6638 - val_accuracy: 0.6429\n",
      "Epoch 12/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7073 - accuracy: 0.5295 - val_loss: 0.6603 - val_accuracy: 0.6667\n",
      "Epoch 13/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6783 - accuracy: 0.5992 - val_loss: 0.6582 - val_accuracy: 0.6667\n",
      "Epoch 14/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6572 - accuracy: 0.5976 - val_loss: 0.6571 - val_accuracy: 0.6667\n",
      "Epoch 15/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6928 - accuracy: 0.5650 - val_loss: 0.6550 - val_accuracy: 0.6667\n",
      "Epoch 16/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6515 - accuracy: 0.6012 - val_loss: 0.6526 - val_accuracy: 0.6667\n",
      "Epoch 17/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6506 - accuracy: 0.6214 - val_loss: 0.6525 - val_accuracy: 0.6667\n",
      "Epoch 18/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6874 - accuracy: 0.5818 - val_loss: 0.6508 - val_accuracy: 0.6667\n",
      "Epoch 19/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6563 - accuracy: 0.6297 - val_loss: 0.6475 - val_accuracy: 0.6667\n",
      "Epoch 20/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.5909 - accuracy: 0.7095 - val_loss: 0.6459 - val_accuracy: 0.6667\n",
      "Epoch 21/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6421 - accuracy: 0.6353 - val_loss: 0.6449 - val_accuracy: 0.6667\n",
      "Epoch 22/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6537 - accuracy: 0.5981 - val_loss: 0.6428 - val_accuracy: 0.6667\n",
      "Epoch 23/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6350 - accuracy: 0.6079 - val_loss: 0.6399 - val_accuracy: 0.6667\n",
      "Epoch 24/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6502 - accuracy: 0.5934 - val_loss: 0.6404 - val_accuracy: 0.6667\n",
      "Epoch 25/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6446 - accuracy: 0.6273 - val_loss: 0.6385 - val_accuracy: 0.6905\n",
      "Epoch 26/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6909 - accuracy: 0.5725 - val_loss: 0.6369 - val_accuracy: 0.6905\n",
      "Epoch 27/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6479 - accuracy: 0.6339 - val_loss: 0.6349 - val_accuracy: 0.6905\n",
      "Epoch 28/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6399 - accuracy: 0.6526 - val_loss: 0.6348 - val_accuracy: 0.6667\n",
      "Epoch 29/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6761 - accuracy: 0.5990 - val_loss: 0.6331 - val_accuracy: 0.6905\n",
      "Epoch 30/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6469 - accuracy: 0.6026 - val_loss: 0.6314 - val_accuracy: 0.6667\n",
      "Epoch 31/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6720 - accuracy: 0.5978 - val_loss: 0.6314 - val_accuracy: 0.6905\n",
      "Epoch 32/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6223 - accuracy: 0.6507 - val_loss: 0.6296 - val_accuracy: 0.6905\n",
      "Epoch 33/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6250 - accuracy: 0.6674 - val_loss: 0.6285 - val_accuracy: 0.6905\n",
      "Epoch 34/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6678 - accuracy: 0.6299 - val_loss: 0.6274 - val_accuracy: 0.7143\n",
      "Epoch 35/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6461 - accuracy: 0.6226 - val_loss: 0.6256 - val_accuracy: 0.6667\n",
      "Epoch 36/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6547 - accuracy: 0.6141 - val_loss: 0.6241 - val_accuracy: 0.7143\n",
      "Epoch 37/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6505 - accuracy: 0.6325 - val_loss: 0.6231 - val_accuracy: 0.6667\n",
      "Epoch 38/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6138 - accuracy: 0.6410 - val_loss: 0.6231 - val_accuracy: 0.6667\n",
      "Epoch 39/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6071 - accuracy: 0.6477 - val_loss: 0.6209 - val_accuracy: 0.6905\n",
      "Epoch 40/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6293 - accuracy: 0.6755 - val_loss: 0.6202 - val_accuracy: 0.6667\n",
      "Epoch 41/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6045 - accuracy: 0.6893 - val_loss: 0.6191 - val_accuracy: 0.7143\n",
      "Epoch 42/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6461 - accuracy: 0.5971 - val_loss: 0.6169 - val_accuracy: 0.7143\n",
      "Epoch 43/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6135 - accuracy: 0.6823 - val_loss: 0.6162 - val_accuracy: 0.7143\n",
      "Epoch 44/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6066 - accuracy: 0.6455 - val_loss: 0.6165 - val_accuracy: 0.6905\n",
      "Epoch 45/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6245 - accuracy: 0.6506 - val_loss: 0.6145 - val_accuracy: 0.7143\n",
      "Epoch 46/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6075 - accuracy: 0.6728 - val_loss: 0.6135 - val_accuracy: 0.6905\n",
      "Epoch 47/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6130 - accuracy: 0.6832 - val_loss: 0.6121 - val_accuracy: 0.7143\n",
      "Epoch 48/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6507 - accuracy: 0.5801 - val_loss: 0.6119 - val_accuracy: 0.6905\n",
      "Epoch 49/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6715 - accuracy: 0.5622 - val_loss: 0.6104 - val_accuracy: 0.7143\n",
      "Epoch 50/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6299 - accuracy: 0.6467 - val_loss: 0.6090 - val_accuracy: 0.6905\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6090 - accuracy: 0.6905\n",
      "Training fold 4/10\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 200, 768, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 200, 768, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 200, 768, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 100, 384, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 100, 384, 64)      6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 100, 384, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 100, 384, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 50, 192, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 50, 192, 128)      24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 50, 192, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 50, 192, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 25, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 25, 96, 256)       98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 25, 96, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 25, 96, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 12, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 12, 48, 512)       393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 12, 48, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 12, 48, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 6, 24, 512)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               18874624  \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 19,534,722\n",
      "Trainable params: 19,532,738\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 4s 11ms/step - loss: 0.8004 - accuracy: 0.4799 - val_loss: 0.6990 - val_accuracy: 0.4762\n",
      "Epoch 2/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6981 - accuracy: 0.5548 - val_loss: 0.6966 - val_accuracy: 0.5476\n",
      "Epoch 3/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6964 - accuracy: 0.5757 - val_loss: 0.6885 - val_accuracy: 0.5952\n",
      "Epoch 4/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6654 - accuracy: 0.5986 - val_loss: 0.6875 - val_accuracy: 0.5714\n",
      "Epoch 5/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7052 - accuracy: 0.5761 - val_loss: 0.6859 - val_accuracy: 0.5714\n",
      "Epoch 6/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6783 - accuracy: 0.5942 - val_loss: 0.6846 - val_accuracy: 0.5714\n",
      "Epoch 7/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6590 - accuracy: 0.6343 - val_loss: 0.6856 - val_accuracy: 0.5714\n",
      "Epoch 8/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7224 - accuracy: 0.5497 - val_loss: 0.6843 - val_accuracy: 0.5714\n",
      "Epoch 9/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6816 - accuracy: 0.5591 - val_loss: 0.6823 - val_accuracy: 0.5714\n",
      "Epoch 10/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7157 - accuracy: 0.5099 - val_loss: 0.6820 - val_accuracy: 0.5714\n",
      "Epoch 11/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6966 - accuracy: 0.5373 - val_loss: 0.6813 - val_accuracy: 0.5714\n",
      "Epoch 12/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6508 - accuracy: 0.6382 - val_loss: 0.6789 - val_accuracy: 0.5952\n",
      "Epoch 13/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6818 - accuracy: 0.6039 - val_loss: 0.6787 - val_accuracy: 0.5714\n",
      "Epoch 14/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6832 - accuracy: 0.5623 - val_loss: 0.6778 - val_accuracy: 0.5714\n",
      "Epoch 15/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6510 - accuracy: 0.5904 - val_loss: 0.6784 - val_accuracy: 0.5714\n",
      "Epoch 16/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6825 - accuracy: 0.5912 - val_loss: 0.6769 - val_accuracy: 0.5714\n",
      "Epoch 17/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6683 - accuracy: 0.5698 - val_loss: 0.6775 - val_accuracy: 0.5714\n",
      "Epoch 18/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6793 - accuracy: 0.5592 - val_loss: 0.6765 - val_accuracy: 0.5714\n",
      "Epoch 19/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6714 - accuracy: 0.5630 - val_loss: 0.6774 - val_accuracy: 0.5714\n",
      "Epoch 20/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6921 - accuracy: 0.5207 - val_loss: 0.6745 - val_accuracy: 0.5952\n",
      "Epoch 21/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6751 - accuracy: 0.5591 - val_loss: 0.6744 - val_accuracy: 0.5714\n",
      "Epoch 22/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7003 - accuracy: 0.5232 - val_loss: 0.6732 - val_accuracy: 0.5714\n",
      "Epoch 23/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6454 - accuracy: 0.6150 - val_loss: 0.6729 - val_accuracy: 0.5714\n",
      "Epoch 24/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6527 - accuracy: 0.6203 - val_loss: 0.6720 - val_accuracy: 0.5714\n",
      "Epoch 25/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6692 - accuracy: 0.5510 - val_loss: 0.6705 - val_accuracy: 0.5476\n",
      "Epoch 26/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6430 - accuracy: 0.6081 - val_loss: 0.6727 - val_accuracy: 0.5476\n",
      "Epoch 27/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6626 - accuracy: 0.6072 - val_loss: 0.6722 - val_accuracy: 0.5714\n",
      "Epoch 28/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6330 - accuracy: 0.6230 - val_loss: 0.6733 - val_accuracy: 0.5476\n",
      "Epoch 29/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6886 - accuracy: 0.5929 - val_loss: 0.6718 - val_accuracy: 0.5714\n",
      "Epoch 30/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6691 - accuracy: 0.5884 - val_loss: 0.6708 - val_accuracy: 0.5476\n",
      "Epoch 31/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6358 - accuracy: 0.6432 - val_loss: 0.6732 - val_accuracy: 0.5476\n",
      "Epoch 32/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6494 - accuracy: 0.5699 - val_loss: 0.6694 - val_accuracy: 0.5476\n",
      "Epoch 33/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6448 - accuracy: 0.6177 - val_loss: 0.6684 - val_accuracy: 0.5714\n",
      "Epoch 34/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6015 - accuracy: 0.6983 - val_loss: 0.6684 - val_accuracy: 0.5476\n",
      "Epoch 35/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6651 - accuracy: 0.6572 - val_loss: 0.6683 - val_accuracy: 0.5714\n",
      "Epoch 36/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6668 - accuracy: 0.6309 - val_loss: 0.6678 - val_accuracy: 0.5714\n",
      "Epoch 37/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6443 - accuracy: 0.6032 - val_loss: 0.6674 - val_accuracy: 0.5714\n",
      "Epoch 38/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6428 - accuracy: 0.5746 - val_loss: 0.6669 - val_accuracy: 0.5714\n",
      "Epoch 39/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6371 - accuracy: 0.6311 - val_loss: 0.6668 - val_accuracy: 0.5714\n",
      "Epoch 40/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.5945 - accuracy: 0.6298 - val_loss: 0.6653 - val_accuracy: 0.5714\n",
      "Epoch 41/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6486 - accuracy: 0.6292 - val_loss: 0.6640 - val_accuracy: 0.5476\n",
      "Epoch 42/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6185 - accuracy: 0.6392 - val_loss: 0.6628 - val_accuracy: 0.5714\n",
      "Epoch 43/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6379 - accuracy: 0.6284 - val_loss: 0.6631 - val_accuracy: 0.5476\n",
      "Epoch 44/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6473 - accuracy: 0.6058 - val_loss: 0.6632 - val_accuracy: 0.5714\n",
      "Epoch 45/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6630 - accuracy: 0.6402 - val_loss: 0.6616 - val_accuracy: 0.5476\n",
      "Epoch 46/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6486 - accuracy: 0.6103 - val_loss: 0.6602 - val_accuracy: 0.5714\n",
      "Epoch 47/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6427 - accuracy: 0.6247 - val_loss: 0.6612 - val_accuracy: 0.5476\n",
      "Epoch 48/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6363 - accuracy: 0.6224 - val_loss: 0.6622 - val_accuracy: 0.5714\n",
      "Epoch 49/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6366 - accuracy: 0.6420 - val_loss: 0.6602 - val_accuracy: 0.5476\n",
      "Epoch 50/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6262 - accuracy: 0.6336 - val_loss: 0.6623 - val_accuracy: 0.5476\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6623 - accuracy: 0.5476\n",
      "Training fold 5/10\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 200, 768, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 200, 768, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 200, 768, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 100, 384, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 100, 384, 64)      6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 100, 384, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 100, 384, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 50, 192, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 50, 192, 128)      24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 50, 192, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 50, 192, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 25, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 25, 96, 256)       98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 25, 96, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 25, 96, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 12, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 12, 48, 512)       393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 12, 48, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 12, 48, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 6, 24, 512)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               18874624  \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 19,534,722\n",
      "Trainable params: 19,532,738\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 4s 11ms/step - loss: 0.7524 - accuracy: 0.4157 - val_loss: 0.6695 - val_accuracy: 0.5952\n",
      "Epoch 2/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.7211 - accuracy: 0.4770 - val_loss: 0.6569 - val_accuracy: 0.5476\n",
      "Epoch 3/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7109 - accuracy: 0.5247 - val_loss: 0.6676 - val_accuracy: 0.5476\n",
      "Epoch 4/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7331 - accuracy: 0.4680 - val_loss: 0.6665 - val_accuracy: 0.5238\n",
      "Epoch 5/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7104 - accuracy: 0.5238 - val_loss: 0.6649 - val_accuracy: 0.5238\n",
      "Epoch 6/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7034 - accuracy: 0.5473 - val_loss: 0.6649 - val_accuracy: 0.5476\n",
      "Epoch 7/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6754 - accuracy: 0.5774 - val_loss: 0.6638 - val_accuracy: 0.5476\n",
      "Epoch 8/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6757 - accuracy: 0.5490 - val_loss: 0.6619 - val_accuracy: 0.5476\n",
      "Epoch 9/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6557 - accuracy: 0.6122 - val_loss: 0.6591 - val_accuracy: 0.5476\n",
      "Epoch 10/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7001 - accuracy: 0.5425 - val_loss: 0.6572 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6752 - accuracy: 0.5783 - val_loss: 0.6542 - val_accuracy: 0.5476\n",
      "Epoch 12/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6778 - accuracy: 0.5689 - val_loss: 0.6550 - val_accuracy: 0.5714\n",
      "Epoch 13/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6974 - accuracy: 0.5342 - val_loss: 0.6511 - val_accuracy: 0.5476\n",
      "Epoch 14/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6623 - accuracy: 0.5697 - val_loss: 0.6507 - val_accuracy: 0.5476\n",
      "Epoch 15/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6985 - accuracy: 0.5391 - val_loss: 0.6524 - val_accuracy: 0.5952\n",
      "Epoch 16/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6773 - accuracy: 0.5676 - val_loss: 0.6510 - val_accuracy: 0.6190\n",
      "Epoch 17/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6978 - accuracy: 0.5440 - val_loss: 0.6480 - val_accuracy: 0.6190\n",
      "Epoch 18/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6532 - accuracy: 0.5932 - val_loss: 0.6448 - val_accuracy: 0.6667\n",
      "Epoch 19/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6711 - accuracy: 0.5787 - val_loss: 0.6465 - val_accuracy: 0.6429\n",
      "Epoch 20/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6666 - accuracy: 0.5537 - val_loss: 0.6397 - val_accuracy: 0.6905\n",
      "Epoch 21/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6573 - accuracy: 0.6318 - val_loss: 0.6413 - val_accuracy: 0.6667\n",
      "Epoch 22/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6544 - accuracy: 0.6006 - val_loss: 0.6424 - val_accuracy: 0.6905\n",
      "Epoch 23/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6338 - accuracy: 0.6359 - val_loss: 0.6415 - val_accuracy: 0.6905\n",
      "Epoch 24/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6762 - accuracy: 0.5719 - val_loss: 0.6397 - val_accuracy: 0.6905\n",
      "Epoch 25/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6799 - accuracy: 0.5581 - val_loss: 0.6376 - val_accuracy: 0.6905\n",
      "Epoch 26/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6631 - accuracy: 0.5753 - val_loss: 0.6351 - val_accuracy: 0.6905\n",
      "Epoch 27/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6557 - accuracy: 0.6059 - val_loss: 0.6348 - val_accuracy: 0.6905\n",
      "Epoch 28/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6292 - accuracy: 0.6754 - val_loss: 0.6362 - val_accuracy: 0.6905\n",
      "Epoch 29/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6587 - accuracy: 0.5912 - val_loss: 0.6333 - val_accuracy: 0.6905\n",
      "Epoch 30/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6424 - accuracy: 0.6359 - val_loss: 0.6342 - val_accuracy: 0.6905\n",
      "Epoch 31/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6467 - accuracy: 0.5919 - val_loss: 0.6330 - val_accuracy: 0.7143\n",
      "Epoch 32/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6514 - accuracy: 0.6057 - val_loss: 0.6345 - val_accuracy: 0.6667\n",
      "Epoch 33/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6468 - accuracy: 0.6310 - val_loss: 0.6312 - val_accuracy: 0.6667\n",
      "Epoch 34/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6397 - accuracy: 0.6462 - val_loss: 0.6292 - val_accuracy: 0.6667\n",
      "Epoch 35/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6373 - accuracy: 0.6426 - val_loss: 0.6296 - val_accuracy: 0.6667\n",
      "Epoch 36/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6470 - accuracy: 0.6258 - val_loss: 0.6286 - val_accuracy: 0.6667\n",
      "Epoch 37/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6206 - accuracy: 0.6775 - val_loss: 0.6274 - val_accuracy: 0.6667\n",
      "Epoch 38/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6671 - accuracy: 0.6087 - val_loss: 0.6245 - val_accuracy: 0.6905\n",
      "Epoch 39/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6281 - accuracy: 0.6361 - val_loss: 0.6234 - val_accuracy: 0.6667\n",
      "Epoch 40/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6332 - accuracy: 0.6140 - val_loss: 0.6219 - val_accuracy: 0.6905\n",
      "Epoch 41/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6538 - accuracy: 0.6300 - val_loss: 0.6200 - val_accuracy: 0.6905\n",
      "Epoch 42/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6338 - accuracy: 0.6440 - val_loss: 0.6184 - val_accuracy: 0.6905\n",
      "Epoch 43/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6085 - accuracy: 0.6881 - val_loss: 0.6174 - val_accuracy: 0.6905\n",
      "Epoch 44/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6278 - accuracy: 0.6245 - val_loss: 0.6149 - val_accuracy: 0.6905\n",
      "Epoch 45/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6379 - accuracy: 0.6226 - val_loss: 0.6145 - val_accuracy: 0.6905\n",
      "Epoch 46/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6071 - accuracy: 0.6956 - val_loss: 0.6124 - val_accuracy: 0.6905\n",
      "Epoch 47/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6384 - accuracy: 0.6516 - val_loss: 0.6129 - val_accuracy: 0.6667\n",
      "Epoch 48/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6166 - accuracy: 0.6578 - val_loss: 0.6130 - val_accuracy: 0.6667\n",
      "Epoch 49/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6567 - accuracy: 0.5893 - val_loss: 0.6105 - val_accuracy: 0.6667\n",
      "Epoch 50/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.5951 - accuracy: 0.7161 - val_loss: 0.6090 - val_accuracy: 0.6667\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6090 - accuracy: 0.6667\n",
      "Training fold 6/10\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 200, 768, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 200, 768, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 200, 768, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 100, 384, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 100, 384, 64)      6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 100, 384, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 100, 384, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 50, 192, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 50, 192, 128)      24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 50, 192, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 50, 192, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 25, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 25, 96, 256)       98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 25, 96, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 25, 96, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 12, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 12, 48, 512)       393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 12, 48, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 12, 48, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 6, 24, 512)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 256)               18874624  \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 19,534,722\n",
      "Trainable params: 19,532,738\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 4s 11ms/step - loss: 0.8430 - accuracy: 0.5265 - val_loss: 0.7377 - val_accuracy: 0.4762\n",
      "Epoch 2/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7196 - accuracy: 0.5300 - val_loss: 0.7346 - val_accuracy: 0.5952\n",
      "Epoch 3/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7109 - accuracy: 0.5019 - val_loss: 0.7114 - val_accuracy: 0.5714\n",
      "Epoch 4/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6811 - accuracy: 0.5610 - val_loss: 0.7101 - val_accuracy: 0.5714\n",
      "Epoch 5/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7345 - accuracy: 0.4765 - val_loss: 0.7049 - val_accuracy: 0.6190\n",
      "Epoch 6/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7081 - accuracy: 0.5038 - val_loss: 0.7019 - val_accuracy: 0.6190\n",
      "Epoch 7/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7002 - accuracy: 0.5094 - val_loss: 0.6985 - val_accuracy: 0.6190\n",
      "Epoch 8/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7055 - accuracy: 0.5316 - val_loss: 0.6950 - val_accuracy: 0.6190\n",
      "Epoch 9/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6920 - accuracy: 0.5248 - val_loss: 0.6895 - val_accuracy: 0.6190\n",
      "Epoch 10/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7011 - accuracy: 0.5662 - val_loss: 0.6873 - val_accuracy: 0.6429\n",
      "Epoch 11/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6897 - accuracy: 0.5577 - val_loss: 0.6834 - val_accuracy: 0.6429\n",
      "Epoch 12/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6678 - accuracy: 0.5998 - val_loss: 0.6864 - val_accuracy: 0.5714\n",
      "Epoch 13/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6957 - accuracy: 0.5631 - val_loss: 0.6820 - val_accuracy: 0.6190\n",
      "Epoch 14/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6700 - accuracy: 0.6009 - val_loss: 0.6778 - val_accuracy: 0.6190\n",
      "Epoch 15/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7454 - accuracy: 0.4474 - val_loss: 0.6817 - val_accuracy: 0.5952\n",
      "Epoch 16/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6615 - accuracy: 0.6216 - val_loss: 0.6770 - val_accuracy: 0.5952\n",
      "Epoch 17/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6794 - accuracy: 0.5600 - val_loss: 0.6810 - val_accuracy: 0.5714\n",
      "Epoch 18/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6828 - accuracy: 0.5792 - val_loss: 0.6681 - val_accuracy: 0.5952\n",
      "Epoch 19/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6713 - accuracy: 0.5648 - val_loss: 0.6640 - val_accuracy: 0.6190\n",
      "Epoch 20/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6451 - accuracy: 0.6434 - val_loss: 0.6697 - val_accuracy: 0.6190\n",
      "Epoch 21/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6737 - accuracy: 0.5648 - val_loss: 0.6683 - val_accuracy: 0.5952\n",
      "Epoch 22/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6383 - accuracy: 0.6154 - val_loss: 0.6666 - val_accuracy: 0.6429\n",
      "Epoch 23/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6727 - accuracy: 0.5953 - val_loss: 0.6648 - val_accuracy: 0.6190\n",
      "Epoch 24/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6693 - accuracy: 0.5572 - val_loss: 0.6609 - val_accuracy: 0.6429\n",
      "Epoch 25/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6811 - accuracy: 0.5659 - val_loss: 0.6573 - val_accuracy: 0.6905\n",
      "Epoch 26/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6644 - accuracy: 0.5747 - val_loss: 0.6575 - val_accuracy: 0.7381\n",
      "Epoch 27/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6509 - accuracy: 0.5758 - val_loss: 0.6541 - val_accuracy: 0.7143\n",
      "Epoch 28/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6604 - accuracy: 0.6091 - val_loss: 0.6500 - val_accuracy: 0.6905\n",
      "Epoch 29/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6532 - accuracy: 0.6066 - val_loss: 0.6571 - val_accuracy: 0.7143\n",
      "Epoch 30/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6497 - accuracy: 0.5916 - val_loss: 0.6477 - val_accuracy: 0.6905\n",
      "Epoch 31/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6447 - accuracy: 0.6325 - val_loss: 0.6455 - val_accuracy: 0.6905\n",
      "Epoch 32/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6672 - accuracy: 0.6023 - val_loss: 0.6415 - val_accuracy: 0.6667\n",
      "Epoch 33/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6422 - accuracy: 0.6333 - val_loss: 0.6443 - val_accuracy: 0.6905\n",
      "Epoch 34/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6585 - accuracy: 0.6139 - val_loss: 0.6383 - val_accuracy: 0.7143\n",
      "Epoch 35/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6577 - accuracy: 0.6039 - val_loss: 0.6410 - val_accuracy: 0.7143\n",
      "Epoch 36/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6662 - accuracy: 0.6046 - val_loss: 0.6394 - val_accuracy: 0.7143\n",
      "Epoch 37/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6219 - accuracy: 0.6642 - val_loss: 0.6400 - val_accuracy: 0.7143\n",
      "Epoch 38/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6549 - accuracy: 0.6226 - val_loss: 0.6377 - val_accuracy: 0.7143\n",
      "Epoch 39/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6288 - accuracy: 0.6653 - val_loss: 0.6386 - val_accuracy: 0.7143\n",
      "Epoch 40/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6403 - accuracy: 0.6265 - val_loss: 0.6361 - val_accuracy: 0.7143\n",
      "Epoch 41/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6432 - accuracy: 0.6500 - val_loss: 0.6372 - val_accuracy: 0.7143\n",
      "Epoch 42/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6459 - accuracy: 0.6154 - val_loss: 0.6402 - val_accuracy: 0.7143\n",
      "Epoch 43/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6412 - accuracy: 0.5939 - val_loss: 0.6311 - val_accuracy: 0.7143\n",
      "Epoch 44/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6408 - accuracy: 0.6059 - val_loss: 0.6348 - val_accuracy: 0.7381\n",
      "Epoch 45/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6405 - accuracy: 0.6439 - val_loss: 0.6325 - val_accuracy: 0.7381\n",
      "Epoch 46/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6311 - accuracy: 0.6210 - val_loss: 0.6299 - val_accuracy: 0.7143\n",
      "Epoch 47/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6549 - accuracy: 0.6152 - val_loss: 0.6303 - val_accuracy: 0.7143\n",
      "Epoch 48/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6406 - accuracy: 0.6481 - val_loss: 0.6306 - val_accuracy: 0.7143\n",
      "Epoch 49/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6513 - accuracy: 0.6016 - val_loss: 0.6321 - val_accuracy: 0.7143\n",
      "Epoch 50/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6625 - accuracy: 0.5907 - val_loss: 0.6215 - val_accuracy: 0.7143\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6215 - accuracy: 0.7143\n",
      "Training fold 7/10\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_35 (Conv2D)           (None, 200, 768, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 200, 768, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 200, 768, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 100, 384, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 100, 384, 64)      6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 100, 384, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 100, 384, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 50, 192, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 50, 192, 128)      24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 50, 192, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 50, 192, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 25, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 25, 96, 256)       98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 25, 96, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 25, 96, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 12, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 12, 48, 512)       393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 12, 48, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 12, 48, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 6, 24, 512)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               18874624  \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 19,534,722\n",
      "Trainable params: 19,532,738\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 4s 11ms/step - loss: 0.8945 - accuracy: 0.4917 - val_loss: 0.7840 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7535 - accuracy: 0.4749 - val_loss: 0.6554 - val_accuracy: 0.6429\n",
      "Epoch 3/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7510 - accuracy: 0.4748 - val_loss: 0.6520 - val_accuracy: 0.5714\n",
      "Epoch 4/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7276 - accuracy: 0.4992 - val_loss: 0.6506 - val_accuracy: 0.5714\n",
      "Epoch 5/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7325 - accuracy: 0.4647 - val_loss: 0.6463 - val_accuracy: 0.5476\n",
      "Epoch 6/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7094 - accuracy: 0.4995 - val_loss: 0.6480 - val_accuracy: 0.5714\n",
      "Epoch 7/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7195 - accuracy: 0.5129 - val_loss: 0.6481 - val_accuracy: 0.5952\n",
      "Epoch 8/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7051 - accuracy: 0.5252 - val_loss: 0.6463 - val_accuracy: 0.5714\n",
      "Epoch 9/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6911 - accuracy: 0.5689 - val_loss: 0.6457 - val_accuracy: 0.5952\n",
      "Epoch 10/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7109 - accuracy: 0.4708 - val_loss: 0.6460 - val_accuracy: 0.5952\n",
      "Epoch 11/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6930 - accuracy: 0.5470 - val_loss: 0.6437 - val_accuracy: 0.5952\n",
      "Epoch 12/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7162 - accuracy: 0.5241 - val_loss: 0.6445 - val_accuracy: 0.5952\n",
      "Epoch 13/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7264 - accuracy: 0.4691 - val_loss: 0.6435 - val_accuracy: 0.5952\n",
      "Epoch 14/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6950 - accuracy: 0.5316 - val_loss: 0.6448 - val_accuracy: 0.6190\n",
      "Epoch 15/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6900 - accuracy: 0.5365 - val_loss: 0.6462 - val_accuracy: 0.6190\n",
      "Epoch 16/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6912 - accuracy: 0.5747 - val_loss: 0.6434 - val_accuracy: 0.5714\n",
      "Epoch 17/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.7012 - accuracy: 0.5205 - val_loss: 0.6446 - val_accuracy: 0.5952\n",
      "Epoch 18/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6796 - accuracy: 0.5393 - val_loss: 0.6397 - val_accuracy: 0.6190\n",
      "Epoch 19/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6573 - accuracy: 0.5707 - val_loss: 0.6431 - val_accuracy: 0.6190\n",
      "Epoch 20/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6607 - accuracy: 0.6065 - val_loss: 0.6408 - val_accuracy: 0.6190\n",
      "Epoch 21/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6983 - accuracy: 0.5435 - val_loss: 0.6410 - val_accuracy: 0.6190\n",
      "Epoch 22/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7057 - accuracy: 0.5413 - val_loss: 0.6370 - val_accuracy: 0.6190\n",
      "Epoch 23/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6626 - accuracy: 0.5951 - val_loss: 0.6383 - val_accuracy: 0.6190\n",
      "Epoch 24/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7095 - accuracy: 0.5165 - val_loss: 0.6363 - val_accuracy: 0.6429\n",
      "Epoch 25/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6624 - accuracy: 0.5839 - val_loss: 0.6362 - val_accuracy: 0.6667\n",
      "Epoch 26/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6705 - accuracy: 0.5769 - val_loss: 0.6395 - val_accuracy: 0.6429\n",
      "Epoch 27/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6901 - accuracy: 0.5391 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 28/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7075 - accuracy: 0.5347 - val_loss: 0.6378 - val_accuracy: 0.6667\n",
      "Epoch 29/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6822 - accuracy: 0.5908 - val_loss: 0.6354 - val_accuracy: 0.6667\n",
      "Epoch 30/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6972 - accuracy: 0.5419 - val_loss: 0.6337 - val_accuracy: 0.6905\n",
      "Epoch 31/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6950 - accuracy: 0.5776 - val_loss: 0.6337 - val_accuracy: 0.7143\n",
      "Epoch 32/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6730 - accuracy: 0.5955 - val_loss: 0.6355 - val_accuracy: 0.6905\n",
      "Epoch 33/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6725 - accuracy: 0.6250 - val_loss: 0.6340 - val_accuracy: 0.6905\n",
      "Epoch 34/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6542 - accuracy: 0.6027 - val_loss: 0.6335 - val_accuracy: 0.6905\n",
      "Epoch 35/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6424 - accuracy: 0.6594 - val_loss: 0.6327 - val_accuracy: 0.7143\n",
      "Epoch 36/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6484 - accuracy: 0.6901 - val_loss: 0.6322 - val_accuracy: 0.7143\n",
      "Epoch 37/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6599 - accuracy: 0.5807 - val_loss: 0.6338 - val_accuracy: 0.7143\n",
      "Epoch 38/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6432 - accuracy: 0.5843 - val_loss: 0.6309 - val_accuracy: 0.7381\n",
      "Epoch 39/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6419 - accuracy: 0.6346 - val_loss: 0.6342 - val_accuracy: 0.7143\n",
      "Epoch 40/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6372 - accuracy: 0.6255 - val_loss: 0.6313 - val_accuracy: 0.7381\n",
      "Epoch 41/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6926 - accuracy: 0.5676 - val_loss: 0.6314 - val_accuracy: 0.7381\n",
      "Epoch 42/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6311 - accuracy: 0.6505 - val_loss: 0.6302 - val_accuracy: 0.7381\n",
      "Epoch 43/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6558 - accuracy: 0.5830 - val_loss: 0.6285 - val_accuracy: 0.7381\n",
      "Epoch 44/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6528 - accuracy: 0.6046 - val_loss: 0.6308 - val_accuracy: 0.6905\n",
      "Epoch 45/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6375 - accuracy: 0.6057 - val_loss: 0.6279 - val_accuracy: 0.7143\n",
      "Epoch 46/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6359 - accuracy: 0.6516 - val_loss: 0.6304 - val_accuracy: 0.7143\n",
      "Epoch 47/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6525 - accuracy: 0.5868 - val_loss: 0.6282 - val_accuracy: 0.7143\n",
      "Epoch 48/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6113 - accuracy: 0.6804 - val_loss: 0.6275 - val_accuracy: 0.7143\n",
      "Epoch 49/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6473 - accuracy: 0.5933 - val_loss: 0.6265 - val_accuracy: 0.7143\n",
      "Epoch 50/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6410 - accuracy: 0.6274 - val_loss: 0.6270 - val_accuracy: 0.7143\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6270 - accuracy: 0.7143\n",
      "Training fold 8/10\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 200, 768, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 200, 768, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 200, 768, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 100, 384, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 100, 384, 64)      6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 100, 384, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 100, 384, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 50, 192, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 50, 192, 128)      24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 50, 192, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 50, 192, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 25, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 25, 96, 256)       98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 25, 96, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 25, 96, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 12, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 12, 48, 512)       393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 12, 48, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 12, 48, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 6, 24, 512)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 256)               18874624  \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 19,534,722\n",
      "Trainable params: 19,532,738\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 4s 11ms/step - loss: 0.7487 - accuracy: 0.5531 - val_loss: 0.7458 - val_accuracy: 0.4048\n",
      "Epoch 2/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7545 - accuracy: 0.4679 - val_loss: 0.7023 - val_accuracy: 0.5476\n",
      "Epoch 3/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7125 - accuracy: 0.5129 - val_loss: 0.6944 - val_accuracy: 0.5476\n",
      "Epoch 4/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7401 - accuracy: 0.4558 - val_loss: 0.6917 - val_accuracy: 0.5476\n",
      "Epoch 5/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7200 - accuracy: 0.5214 - val_loss: 0.6888 - val_accuracy: 0.5476\n",
      "Epoch 6/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7010 - accuracy: 0.5322 - val_loss: 0.6870 - val_accuracy: 0.5476\n",
      "Epoch 7/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7289 - accuracy: 0.5206 - val_loss: 0.6828 - val_accuracy: 0.5476\n",
      "Epoch 8/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7053 - accuracy: 0.5991 - val_loss: 0.6825 - val_accuracy: 0.5714\n",
      "Epoch 9/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6925 - accuracy: 0.6039 - val_loss: 0.6798 - val_accuracy: 0.5714\n",
      "Epoch 10/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7583 - accuracy: 0.4365 - val_loss: 0.6771 - val_accuracy: 0.5714\n",
      "Epoch 11/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7071 - accuracy: 0.5375 - val_loss: 0.6756 - val_accuracy: 0.5714\n",
      "Epoch 12/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7199 - accuracy: 0.5552 - val_loss: 0.6745 - val_accuracy: 0.5714\n",
      "Epoch 13/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6736 - accuracy: 0.5743 - val_loss: 0.6735 - val_accuracy: 0.5714\n",
      "Epoch 14/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6879 - accuracy: 0.5714 - val_loss: 0.6718 - val_accuracy: 0.5476\n",
      "Epoch 15/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6991 - accuracy: 0.5549 - val_loss: 0.6697 - val_accuracy: 0.5476\n",
      "Epoch 16/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6889 - accuracy: 0.5626 - val_loss: 0.6669 - val_accuracy: 0.5714\n",
      "Epoch 17/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.7287 - accuracy: 0.4952 - val_loss: 0.6655 - val_accuracy: 0.5714\n",
      "Epoch 18/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6768 - accuracy: 0.5746 - val_loss: 0.6627 - val_accuracy: 0.5952\n",
      "Epoch 19/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7097 - accuracy: 0.5151 - val_loss: 0.6635 - val_accuracy: 0.5714\n",
      "Epoch 20/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6667 - accuracy: 0.6336 - val_loss: 0.6628 - val_accuracy: 0.5952\n",
      "Epoch 21/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6910 - accuracy: 0.5893 - val_loss: 0.6608 - val_accuracy: 0.5952\n",
      "Epoch 22/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6505 - accuracy: 0.6547 - val_loss: 0.6587 - val_accuracy: 0.5952\n",
      "Epoch 23/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6641 - accuracy: 0.5972 - val_loss: 0.6576 - val_accuracy: 0.5714\n",
      "Epoch 24/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6816 - accuracy: 0.5533 - val_loss: 0.6555 - val_accuracy: 0.5952\n",
      "Epoch 25/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6810 - accuracy: 0.5910 - val_loss: 0.6548 - val_accuracy: 0.5714\n",
      "Epoch 26/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6189 - accuracy: 0.6447 - val_loss: 0.6536 - val_accuracy: 0.5952\n",
      "Epoch 27/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6431 - accuracy: 0.6060 - val_loss: 0.6514 - val_accuracy: 0.5952\n",
      "Epoch 28/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6881 - accuracy: 0.5608 - val_loss: 0.6496 - val_accuracy: 0.5714\n",
      "Epoch 29/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6460 - accuracy: 0.5846 - val_loss: 0.6479 - val_accuracy: 0.5952\n",
      "Epoch 30/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6655 - accuracy: 0.6296 - val_loss: 0.6489 - val_accuracy: 0.5952\n",
      "Epoch 31/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6682 - accuracy: 0.5817 - val_loss: 0.6488 - val_accuracy: 0.5714\n",
      "Epoch 32/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6954 - accuracy: 0.5796 - val_loss: 0.6476 - val_accuracy: 0.5714\n",
      "Epoch 33/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6558 - accuracy: 0.6142 - val_loss: 0.6453 - val_accuracy: 0.5714\n",
      "Epoch 34/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6532 - accuracy: 0.6285 - val_loss: 0.6444 - val_accuracy: 0.5952\n",
      "Epoch 35/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6361 - accuracy: 0.6359 - val_loss: 0.6425 - val_accuracy: 0.5952\n",
      "Epoch 36/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6634 - accuracy: 0.6198 - val_loss: 0.6405 - val_accuracy: 0.5952\n",
      "Epoch 37/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6633 - accuracy: 0.6012 - val_loss: 0.6403 - val_accuracy: 0.5952\n",
      "Epoch 38/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6078 - accuracy: 0.6539 - val_loss: 0.6383 - val_accuracy: 0.5714\n",
      "Epoch 39/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6487 - accuracy: 0.6131 - val_loss: 0.6393 - val_accuracy: 0.5714\n",
      "Epoch 40/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6414 - accuracy: 0.6224 - val_loss: 0.6369 - val_accuracy: 0.6190\n",
      "Epoch 41/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6213 - accuracy: 0.6725 - val_loss: 0.6356 - val_accuracy: 0.6190\n",
      "Epoch 42/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6306 - accuracy: 0.6321 - val_loss: 0.6357 - val_accuracy: 0.6190\n",
      "Epoch 43/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6268 - accuracy: 0.6413 - val_loss: 0.6321 - val_accuracy: 0.6190\n",
      "Epoch 44/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6201 - accuracy: 0.6512 - val_loss: 0.6337 - val_accuracy: 0.6190\n",
      "Epoch 45/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6662 - accuracy: 0.5913 - val_loss: 0.6304 - val_accuracy: 0.6429\n",
      "Epoch 46/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6311 - accuracy: 0.6286 - val_loss: 0.6317 - val_accuracy: 0.6429\n",
      "Epoch 47/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6557 - accuracy: 0.5952 - val_loss: 0.6314 - val_accuracy: 0.6429\n",
      "Epoch 48/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6371 - accuracy: 0.6536 - val_loss: 0.6284 - val_accuracy: 0.6667\n",
      "Epoch 49/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6279 - accuracy: 0.6201 - val_loss: 0.6287 - val_accuracy: 0.6429\n",
      "Epoch 50/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6172 - accuracy: 0.7004 - val_loss: 0.6261 - val_accuracy: 0.6667\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6261 - accuracy: 0.6667\n",
      "Training fold 9/10\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_45 (Conv2D)           (None, 200, 768, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 200, 768, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 200, 768, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 100, 384, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 100, 384, 64)      6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 100, 384, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 100, 384, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 50, 192, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 50, 192, 128)      24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 50, 192, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 50, 192, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 25, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 25, 96, 256)       98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 25, 96, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 25, 96, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 12, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 12, 48, 512)       393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 12, 48, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 12, 48, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 6, 24, 512)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 256)               18874624  \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 19,534,722\n",
      "Trainable params: 19,532,738\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 5s 11ms/step - loss: 0.6947 - accuracy: 0.5792 - val_loss: 0.7094 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7151 - accuracy: 0.4961 - val_loss: 0.7058 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6992 - accuracy: 0.5644 - val_loss: 0.6978 - val_accuracy: 0.4762\n",
      "Epoch 4/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7023 - accuracy: 0.5424 - val_loss: 0.6964 - val_accuracy: 0.4762\n",
      "Epoch 5/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.7153 - accuracy: 0.5268 - val_loss: 0.6906 - val_accuracy: 0.4762\n",
      "Epoch 6/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6858 - accuracy: 0.5808 - val_loss: 0.6913 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6828 - accuracy: 0.5834 - val_loss: 0.6897 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6656 - accuracy: 0.6578 - val_loss: 0.6844 - val_accuracy: 0.5238\n",
      "Epoch 9/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6968 - accuracy: 0.5519 - val_loss: 0.6847 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6658 - accuracy: 0.5937 - val_loss: 0.6852 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7140 - accuracy: 0.4700 - val_loss: 0.6805 - val_accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6818 - accuracy: 0.5754 - val_loss: 0.6814 - val_accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6893 - accuracy: 0.5726 - val_loss: 0.6762 - val_accuracy: 0.5238\n",
      "Epoch 14/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6594 - accuracy: 0.5525 - val_loss: 0.6698 - val_accuracy: 0.5476\n",
      "Epoch 15/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6623 - accuracy: 0.5889 - val_loss: 0.6710 - val_accuracy: 0.5476\n",
      "Epoch 16/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6875 - accuracy: 0.5698 - val_loss: 0.6723 - val_accuracy: 0.5238\n",
      "Epoch 17/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6491 - accuracy: 0.6271 - val_loss: 0.6690 - val_accuracy: 0.5238\n",
      "Epoch 18/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6727 - accuracy: 0.5654 - val_loss: 0.6695 - val_accuracy: 0.5238\n",
      "Epoch 19/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6789 - accuracy: 0.5704 - val_loss: 0.6627 - val_accuracy: 0.5476\n",
      "Epoch 20/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6708 - accuracy: 0.5866 - val_loss: 0.6633 - val_accuracy: 0.5476\n",
      "Epoch 21/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6479 - accuracy: 0.6195 - val_loss: 0.6611 - val_accuracy: 0.5714\n",
      "Epoch 22/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6569 - accuracy: 0.6222 - val_loss: 0.6593 - val_accuracy: 0.5714\n",
      "Epoch 23/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6504 - accuracy: 0.6130 - val_loss: 0.6573 - val_accuracy: 0.5714\n",
      "Epoch 24/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6507 - accuracy: 0.6018 - val_loss: 0.6562 - val_accuracy: 0.5952\n",
      "Epoch 25/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6661 - accuracy: 0.5900 - val_loss: 0.6529 - val_accuracy: 0.5952\n",
      "Epoch 26/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6599 - accuracy: 0.6041 - val_loss: 0.6495 - val_accuracy: 0.5952\n",
      "Epoch 27/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6672 - accuracy: 0.6152 - val_loss: 0.6514 - val_accuracy: 0.5952\n",
      "Epoch 28/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6615 - accuracy: 0.6095 - val_loss: 0.6494 - val_accuracy: 0.5952\n",
      "Epoch 29/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6440 - accuracy: 0.6251 - val_loss: 0.6453 - val_accuracy: 0.5952\n",
      "Epoch 30/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6390 - accuracy: 0.6456 - val_loss: 0.6434 - val_accuracy: 0.5952\n",
      "Epoch 31/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6464 - accuracy: 0.6247 - val_loss: 0.6397 - val_accuracy: 0.5952\n",
      "Epoch 32/50\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.6513 - accuracy: 0.6038 - val_loss: 0.6440 - val_accuracy: 0.5952\n",
      "Epoch 33/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6419 - accuracy: 0.6275 - val_loss: 0.6389 - val_accuracy: 0.6190\n",
      "Epoch 34/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6679 - accuracy: 0.5534 - val_loss: 0.6392 - val_accuracy: 0.6190\n",
      "Epoch 35/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6082 - accuracy: 0.6615 - val_loss: 0.6328 - val_accuracy: 0.6190\n",
      "Epoch 36/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6381 - accuracy: 0.6164 - val_loss: 0.6344 - val_accuracy: 0.6190\n",
      "Epoch 37/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6333 - accuracy: 0.6224 - val_loss: 0.6354 - val_accuracy: 0.6190\n",
      "Epoch 38/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6404 - accuracy: 0.6054 - val_loss: 0.6312 - val_accuracy: 0.6190\n",
      "Epoch 39/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6240 - accuracy: 0.6993 - val_loss: 0.6280 - val_accuracy: 0.6190\n",
      "Epoch 40/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6299 - accuracy: 0.6480 - val_loss: 0.6331 - val_accuracy: 0.6190\n",
      "Epoch 41/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6690 - accuracy: 0.5718 - val_loss: 0.6269 - val_accuracy: 0.6190\n",
      "Epoch 42/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6455 - accuracy: 0.6089 - val_loss: 0.6298 - val_accuracy: 0.6190\n",
      "Epoch 43/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6629 - accuracy: 0.6356 - val_loss: 0.6269 - val_accuracy: 0.6190\n",
      "Epoch 44/50\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.6104 - accuracy: 0.6977 - val_loss: 0.6205 - val_accuracy: 0.6429\n",
      "Epoch 45/50\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.6398 - accuracy: 0.6223 - val_loss: 0.6242 - val_accuracy: 0.6190\n",
      "Epoch 46/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6094 - accuracy: 0.6862 - val_loss: 0.6193 - val_accuracy: 0.6429\n",
      "Epoch 47/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6095 - accuracy: 0.7008 - val_loss: 0.6230 - val_accuracy: 0.6190\n",
      "Epoch 48/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6427 - accuracy: 0.6590 - val_loss: 0.6191 - val_accuracy: 0.6190\n",
      "Epoch 49/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6369 - accuracy: 0.6194 - val_loss: 0.6196 - val_accuracy: 0.6190\n",
      "Epoch 50/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6090 - accuracy: 0.6828 - val_loss: 0.6194 - val_accuracy: 0.6190\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6194 - accuracy: 0.6190\n",
      "Training fold 10/10\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_50 (Conv2D)           (None, 200, 768, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 200, 768, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 200, 768, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 100, 384, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 100, 384, 64)      6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 100, 384, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 100, 384, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 50, 192, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 50, 192, 128)      24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 50, 192, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 50, 192, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 25, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 25, 96, 256)       98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 25, 96, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 25, 96, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 12, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 12, 48, 512)       393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 12, 48, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 12, 48, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 6, 24, 512)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 256)               18874624  \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 19,534,722\n",
      "Trainable params: 19,532,738\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 4s 10ms/step - loss: 0.8377 - accuracy: 0.5117 - val_loss: 0.8745 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7306 - accuracy: 0.5275 - val_loss: 0.6897 - val_accuracy: 0.5476\n",
      "Epoch 3/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7443 - accuracy: 0.4660 - val_loss: 0.6693 - val_accuracy: 0.5476\n",
      "Epoch 4/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7089 - accuracy: 0.5254 - val_loss: 0.6666 - val_accuracy: 0.5714\n",
      "Epoch 5/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6903 - accuracy: 0.5116 - val_loss: 0.6606 - val_accuracy: 0.5952\n",
      "Epoch 6/50\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.6868 - accuracy: 0.5756 - val_loss: 0.6580 - val_accuracy: 0.6429\n",
      "Epoch 7/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6765 - accuracy: 0.5721 - val_loss: 0.6563 - val_accuracy: 0.6429\n",
      "Epoch 8/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7151 - accuracy: 0.5428 - val_loss: 0.6534 - val_accuracy: 0.6667\n",
      "Epoch 9/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.7258 - accuracy: 0.5039 - val_loss: 0.6524 - val_accuracy: 0.6667\n",
      "Epoch 10/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6923 - accuracy: 0.5576 - val_loss: 0.6497 - val_accuracy: 0.6667\n",
      "Epoch 11/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6688 - accuracy: 0.5533 - val_loss: 0.6469 - val_accuracy: 0.6429\n",
      "Epoch 12/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6606 - accuracy: 0.5809 - val_loss: 0.6458 - val_accuracy: 0.6429\n",
      "Epoch 13/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6728 - accuracy: 0.5616 - val_loss: 0.6443 - val_accuracy: 0.6429\n",
      "Epoch 14/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6990 - accuracy: 0.5431 - val_loss: 0.6408 - val_accuracy: 0.6429\n",
      "Epoch 15/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.7009 - accuracy: 0.5554 - val_loss: 0.6393 - val_accuracy: 0.6429\n",
      "Epoch 16/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6717 - accuracy: 0.5581 - val_loss: 0.6356 - val_accuracy: 0.6429\n",
      "Epoch 17/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6603 - accuracy: 0.5896 - val_loss: 0.6351 - val_accuracy: 0.6429\n",
      "Epoch 18/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6682 - accuracy: 0.5844 - val_loss: 0.6350 - val_accuracy: 0.6429\n",
      "Epoch 19/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6444 - accuracy: 0.6314 - val_loss: 0.6321 - val_accuracy: 0.6667\n",
      "Epoch 20/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6692 - accuracy: 0.5867 - val_loss: 0.6290 - val_accuracy: 0.6429\n",
      "Epoch 21/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6874 - accuracy: 0.5785 - val_loss: 0.6278 - val_accuracy: 0.6429\n",
      "Epoch 22/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6766 - accuracy: 0.5439 - val_loss: 0.6232 - val_accuracy: 0.6429\n",
      "Epoch 23/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6381 - accuracy: 0.6168 - val_loss: 0.6222 - val_accuracy: 0.6429\n",
      "Epoch 24/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6965 - accuracy: 0.4996 - val_loss: 0.6198 - val_accuracy: 0.6667\n",
      "Epoch 25/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6553 - accuracy: 0.5999 - val_loss: 0.6185 - val_accuracy: 0.6905\n",
      "Epoch 26/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6575 - accuracy: 0.5963 - val_loss: 0.6174 - val_accuracy: 0.6905\n",
      "Epoch 27/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6840 - accuracy: 0.5677 - val_loss: 0.6160 - val_accuracy: 0.6905\n",
      "Epoch 28/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6701 - accuracy: 0.5665 - val_loss: 0.6145 - val_accuracy: 0.6667\n",
      "Epoch 29/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6632 - accuracy: 0.5839 - val_loss: 0.6126 - val_accuracy: 0.6905\n",
      "Epoch 30/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6485 - accuracy: 0.6131 - val_loss: 0.6105 - val_accuracy: 0.6905\n",
      "Epoch 31/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6571 - accuracy: 0.5966 - val_loss: 0.6077 - val_accuracy: 0.6905\n",
      "Epoch 32/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6848 - accuracy: 0.5594 - val_loss: 0.6071 - val_accuracy: 0.6905\n",
      "Epoch 33/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6549 - accuracy: 0.6227 - val_loss: 0.6063 - val_accuracy: 0.6905\n",
      "Epoch 34/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6265 - accuracy: 0.6465 - val_loss: 0.6051 - val_accuracy: 0.6905\n",
      "Epoch 35/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6377 - accuracy: 0.6690 - val_loss: 0.6032 - val_accuracy: 0.6905\n",
      "Epoch 36/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6661 - accuracy: 0.5855 - val_loss: 0.6012 - val_accuracy: 0.6905\n",
      "Epoch 37/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6480 - accuracy: 0.6309 - val_loss: 0.6001 - val_accuracy: 0.6905\n",
      "Epoch 38/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6536 - accuracy: 0.5698 - val_loss: 0.5980 - val_accuracy: 0.7381\n",
      "Epoch 39/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6769 - accuracy: 0.5711 - val_loss: 0.5987 - val_accuracy: 0.7143\n",
      "Epoch 40/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6486 - accuracy: 0.6125 - val_loss: 0.5967 - val_accuracy: 0.6905\n",
      "Epoch 41/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6362 - accuracy: 0.6341 - val_loss: 0.5970 - val_accuracy: 0.7381\n",
      "Epoch 42/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6427 - accuracy: 0.5856 - val_loss: 0.5941 - val_accuracy: 0.7143\n",
      "Epoch 43/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6144 - accuracy: 0.6120 - val_loss: 0.5921 - val_accuracy: 0.7143\n",
      "Epoch 44/50\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.6503 - accuracy: 0.6347 - val_loss: 0.5902 - val_accuracy: 0.7619\n",
      "Epoch 45/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6538 - accuracy: 0.6121 - val_loss: 0.5909 - val_accuracy: 0.7619\n",
      "Epoch 46/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6255 - accuracy: 0.6339 - val_loss: 0.5880 - val_accuracy: 0.7619\n",
      "Epoch 47/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6692 - accuracy: 0.5768 - val_loss: 0.5873 - val_accuracy: 0.7619\n",
      "Epoch 48/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6203 - accuracy: 0.6454 - val_loss: 0.5872 - val_accuracy: 0.7619\n",
      "Epoch 49/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6255 - accuracy: 0.6737 - val_loss: 0.5845 - val_accuracy: 0.7619\n",
      "Epoch 50/50\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.6523 - accuracy: 0.5947 - val_loss: 0.5840 - val_accuracy: 0.7619\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5840 - accuracy: 0.7619\n",
      "0.6452381044626236 +/- 0.09125604102851778\n"
     ]
    }
   ],
   "source": [
    "folds = 10\n",
    "kfold = StratifiedKFold(n_splits=folds, shuffle=True)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "cv_accuracies = []\n",
    "for index, (train_indices, val_indices) in enumerate(kfold.split(X, y)):\n",
    "    print(f\"Training fold {index+1}/{folds}\")\n",
    "    X_train, X_test = X[train_indices], X[val_indices]\n",
    "    y_train, y_test = y[train_indices], y[val_indices]\n",
    "    \n",
    "    X_train = to_3_channels_np(X_train)\n",
    "    X_test = to_3_channels_np(X_test)\n",
    "    y_train = np.array(one_hot_encode(y_train))\n",
    "    y_test = np.array(one_hot_encode(y_test))\n",
    "    \n",
    "    model = build_model(X_train.shape[1:])\n",
    "    \n",
    "    history=model.fit(datagen.flow(X_train, y_train,batch_size=BATCH_SIZE),\n",
    "                      steps_per_epoch=len(X_train) / BATCH_SIZE, \n",
    "                      epochs=EPOCHS,\n",
    "                      validation_data=(X_test, y_test),\n",
    "                      callbacks=[reduce_lr],\n",
    "                      verbose=1)\n",
    "\n",
    "    ## TEST\n",
    "    scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "    cv_accuracies.append(scores[1])\n",
    "    \n",
    "    del X_train\n",
    "    del X_test\n",
    "    del y_train\n",
    "    del y_test\n",
    "    gc.collect()\n",
    "print(np.mean(cv_accuracies), \"+/-\", np.std(cv_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f801735b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6428571343421936,\n",
       " 0.4285714328289032,\n",
       " 0.6904761791229248,\n",
       " 0.5476190447807312,\n",
       " 0.6666666865348816,\n",
       " 0.7142857313156128,\n",
       " 0.7142857313156128,\n",
       " 0.6666666865348816,\n",
       " 0.6190476417541504,\n",
       " 0.761904776096344]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d5ba7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 200, 768, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 200, 768, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 200, 768, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 100, 384, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 100, 384, 64)      6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100, 384, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100, 384, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 192, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 192, 128)      24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50, 192, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50, 192, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 96, 256)       98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 25, 96, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 25, 96, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 48, 512)       393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 48, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 48, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 24, 512)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               18874624  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 19,534,722\n",
      "Trainable params: 19,532,738\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 14:48:20.085893: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-05-21 14:48:20.086462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-05-21 14:48:20.147680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 14:48:20.147832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:26:00.0 name: NVIDIA GeForce RTX 2070 SUPER computeCapability: 7.5\n",
      "coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2022-05-21 14:48:20.147846: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-05-21 14:48:20.148738: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-05-21 14:48:20.148762: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-05-21 14:48:20.149683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-21 14:48:20.149819: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-21 14:48:20.150605: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-05-21 14:48:20.151001: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-05-21 14:48:20.152769: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-05-21 14:48:20.152873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 14:48:20.153046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 14:48:20.153150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-05-21 14:48:20.153413: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 14:48:20.153842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 14:48:20.153960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:26:00.0 name: NVIDIA GeForce RTX 2070 SUPER computeCapability: 7.5\n",
      "coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2022-05-21 14:48:20.153973: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-05-21 14:48:20.153989: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-05-21 14:48:20.153998: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-05-21 14:48:20.154007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-21 14:48:20.154015: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-21 14:48:20.154023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-05-21 14:48:20.154032: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-05-21 14:48:20.154040: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-05-21 14:48:20.154076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 14:48:20.154211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 14:48:20.154313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-05-21 14:48:20.154332: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-05-21 14:48:20.461713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-05-21 14:48:20.461739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-05-21 14:48:20.461744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-05-21 14:48:20.461934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 14:48:20.462089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 14:48:20.462213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 14:48:20.462318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6752 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:26:00.0, compute capability: 7.5)\n",
      "2022-05-21 14:48:20.462469: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "X_train = to_3_channels_np(np.array(X))\n",
    "y_train = to_categorical(np.array(y), num_classes=num_classes)\n",
    "model = build_model(X_train.shape[1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe2e19bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6406ca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    return 0.1 * (0.5 ** (epoch // 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf8cd8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 14:49:57.829971: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-05-21 14:49:57.844489: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3601025000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 14:49:58.256036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-05-21 14:49:58.390736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-05-21 14:49:58.918573: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-05-21 14:49:58.922309: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential/conv2d/Conv2D (defined at tmp/ipykernel_8329/1888516637.py:1) ]] [Op:__inference_train_function_1775]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mLRS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/alc-tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/alc-tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/anaconda3/envs/alc-tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:888\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    885\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;66;03m# stateless function.\u001b[39;00m\n\u001b[0;32m--> 888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m   _, _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    891\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    892\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/alc-tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2940\u001b[0m   (graph_function,\n\u001b[1;32m   2941\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/alc-tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1914\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1917\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1920\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m     args,\n\u001b[1;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1923\u001b[0m     executing_eagerly)\n\u001b[1;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/alc-tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    554\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    564\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    568\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/alc-tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential/conv2d/Conv2D (defined at tmp/ipykernel_8329/1888516637.py:1) ]] [Op:__inference_train_function_1775]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train,\n",
    "                  steps_per_epoch=len(X_train) / BATCH_SIZE, \n",
    "                  epochs=EPOCHS,\n",
    "                  callbacks=[LRS(scheduler)],\n",
    "                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a612e1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
